{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d079f18",
   "metadata": {},
   "source": [
    "# Model Comparison: XGBoost vs Baseline Models\n",
    "\n",
    "**VenueSignal - AAI-540 Group 6**\n",
    "\n",
    "---\n",
    "\n",
    "This notebook provides a comprehensive comparison between:\n",
    "1. **Baseline Model #1**: Simple Heuristic (avg_review_stars)\n",
    "2. **Baseline Model #2**: Linear Regression (3 features)\n",
    "3. **XGBoost Model**: Parking-focused classifier (leak-free features)\n",
    "\n",
    "**Note**: The baseline models predict continuous star ratings (1.0-5.0) using all features, while XGBoost predicts binary classification (is_highly_rated) using only parking-related features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "708fa46f",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Setup & Configuration\n",
    "\n",
    "### Install/Update Required Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cdf54fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ae44d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install/update required packages for SageMaker\n",
    "!pip3 install -U sagemaker xgboost scikit-learn pandas numpy matplotlib seaborn -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb8aeff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "from time import gmtime, strftime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ML libraries\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import (\n",
    "    mean_squared_error, mean_absolute_error, r2_score,\n",
    "    roc_auc_score, classification_report, confusion_matrix,\n",
    "    f1_score, precision_recall_curve, auc, precision_score, recall_score\n",
    ")\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# AWS & SageMaker libraries\n",
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "# Set display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "# Set visualization style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (14, 6)\n",
    "plt.rcParams['font.size'] = 11\n",
    "\n",
    "print(\"Libraries imported successfully\")\n",
    "print(f\"Timestamp: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c86acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SageMaker Configuration\n",
    "try:\n",
    "    role = get_execution_role()\n",
    "    print(f\"Using SageMaker Execution Role\")\n",
    "except:\n",
    "    # Fallback for local development\n",
    "    role = \"arn:aws:iam::123456789012:role/service-role/AmazonSageMaker-ExecutionRole\"\n",
    "    print(\"WARNING: Using placeholder role (running locally)\")\n",
    "\n",
    "sess = sagemaker.Session()\n",
    "region = sess.boto_region_name\n",
    "bucket = sess.default_bucket()\n",
    "prefix = \"venuesignal-model-comparison\"\n",
    "\n",
    "print(f\"\\nSageMaker Configuration:\")\n",
    "print(f\"  Region: {region}\")\n",
    "print(f\"  S3 Bucket: {bucket}\")\n",
    "print(f\"  Prefix: {prefix}\")\n",
    "print(f\"  Role: {role.split('/')[-1] if '/' in role else role}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03c8a813",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Data Loading & Preparation\n",
    "\n",
    "Load the training dataset from local file system or S3 (if running in SageMaker)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6118ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "# Try multiple locations: local path first, then S3\n",
    "DATA_PATH = 'training_data/split_dataset.csv'\n",
    "\n",
    "print(\"Loading data...\")\n",
    "try:\n",
    "    # Try loading from local path (relative to notebook)\n",
    "    df = pd.read_csv(DATA_PATH)\n",
    "    print(f\"Data loaded from local path: {DATA_PATH}\")\n",
    "except FileNotFoundError:\n",
    "    # Try parent directory\n",
    "    try:\n",
    "        df = pd.read_csv(f'../{DATA_PATH}')\n",
    "        print(f\"Data loaded from parent directory: ../{DATA_PATH}\")\n",
    "    except FileNotFoundError:\n",
    "        # Try S3 if running in SageMaker\n",
    "        try:\n",
    "            s3_path = f's3://{bucket}/{prefix}/data/split_dataset.csv'\n",
    "            df = pd.read_csv(s3_path)\n",
    "            print(f\"Data loaded from S3: {s3_path}\")\n",
    "        except:\n",
    "            raise FileNotFoundError(f\"Could not find data file. Please ensure {DATA_PATH} exists.\")\n",
    "\n",
    "print(f\"\\nData Summary:\")\n",
    "print(f\"  Total records: {len(df):,}\")\n",
    "print(f\"  Features: {df.shape[1]}\")\n",
    "print(f\"\\nSplit distribution:\")\n",
    "print(df['split'].value_counts())\n",
    "print(f\"\\nTarget distribution (is_highly_rated):\")\n",
    "print(df['is_highly_rated'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "896a3a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure target is integer for classification\n",
    "df[\"is_highly_rated\"] = df[\"is_highly_rated\"].astype(int)\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "# Define feature sets\n",
    "TARGET_REGRESSION = \"stars\"\n",
    "TARGET_CLASSIFICATION = \"is_highly_rated\"\n",
    "NON_FEATURES = [\"business_id\", \"split\", TARGET_REGRESSION, TARGET_CLASSIFICATION]\n",
    "\n",
    "# Baseline features (for Linear Regression)\n",
    "BASELINE_FEATURES = ['avg_review_stars', 'enhanced_parking_score', 'review_count']\n",
    "\n",
    "# XGBoost safe features (leak-free, parking-focused)\n",
    "XGBOOST_SAFE_FEATURES = [\n",
    "    \"parking_availability_score\",\n",
    "    \"enhanced_parking_score\",\n",
    "    \"has_parking\",\n",
    "    \"price_range\",\n",
    "    \"parking_mentions\",\n",
    "    \"parking_positive_sentiment\",\n",
    "    \"parking_negative_sentiment\",\n",
    "    \"free_parking_mentions\",\n",
    "    \"valet_mentions\",\n",
    "    \"has_good_parking\",\n",
    "    \"is_restaurant\"\n",
    "]\n",
    "\n",
    "print(\"\\nFeature sets defined:\")\n",
    "print(f\"  Baseline features (regression): {len(BASELINE_FEATURES)}\")\n",
    "print(f\"  XGBoost features (classification): {len(XGBOOST_SAFE_FEATURES)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34bca474",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train/val/test sets\n",
    "train_df = df[df['split'] == 'train'].copy()\n",
    "val_df = df[df['split'] == 'val'].copy()\n",
    "test_df = df[df['split'] == 'test'].copy()\n",
    "\n",
    "print(f\"Data split completed:\")\n",
    "print(f\"  Training:   {len(train_df):,} records ({len(train_df)/len(df)*100:.1f}%)\")\n",
    "print(f\"  Validation: {len(val_df):,} records ({len(val_df)/len(df)*100:.1f}%)\")\n",
    "print(f\"  Test:       {len(test_df):,} records ({len(test_df)/len(df)*100:.1f}%)\")\n",
    "\n",
    "# Verify no data leakage between train and test\n",
    "assert len(set(train_df['business_id']) & set(test_df['business_id'])) == 0, \"Data leakage detected!\"\n",
    "print(\"\\nNo data leakage detected between train and test sets\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e5982d2",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Baseline Model #1: Simple Heuristic\n",
    "\n",
    "**Approach**: Predict star rating using business-level average (`avg_review_stars`)  \n",
    "**Task**: Regression (predicts continuous 1.0-5.0 stars)  \n",
    "**Features**: 1 (avg_review_stars only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "315f4e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"BASELINE MODEL #1: SIMPLE HEURISTIC\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Prepare regression targets\n",
    "y_train_reg = train_df[TARGET_REGRESSION].values\n",
    "y_val_reg = val_df[TARGET_REGRESSION].values\n",
    "y_test_reg = test_df[TARGET_REGRESSION].values\n",
    "\n",
    "# Make predictions using business average\n",
    "y_train_pred_h = train_df['avg_review_stars'].values\n",
    "y_val_pred_h = val_df['avg_review_stars'].values\n",
    "y_test_pred_h = test_df['avg_review_stars'].values\n",
    "\n",
    "# Calculate metrics\n",
    "def calculate_regression_metrics(y_true, y_pred, set_name):\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    within_05 = np.mean(np.abs(y_true - y_pred) <= 0.5) * 100\n",
    "    within_10 = np.mean(np.abs(y_true - y_pred) <= 1.0) * 100\n",
    "    \n",
    "    print(f\"\\n{set_name} Set:\")\n",
    "    print(f\"  RMSE:              {rmse:.4f}\")\n",
    "    print(f\"  MAE:               {mae:.4f}\")\n",
    "    print(f\"  R²:                {r2:.4f}\")\n",
    "    print(f\"  Within 0.5 stars:  {within_05:.1f}%\")\n",
    "    print(f\"  Within 1.0 star:   {within_10:.1f}%\")\n",
    "    \n",
    "    return {'rmse': rmse, 'mae': mae, 'r2': r2, 'within_05': within_05, 'within_10': within_10}\n",
    "\n",
    "train_metrics_h = calculate_regression_metrics(y_train_reg, y_train_pred_h, \"Training\")\n",
    "val_metrics_h = calculate_regression_metrics(y_val_reg, y_val_pred_h, \"Validation\")\n",
    "test_metrics_h = calculate_regression_metrics(y_test_reg, y_test_pred_h, \"Test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaed2b17",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Baseline Model #2: Linear Regression\n",
    "\n",
    "**Approach**: Linear Regression with 3 key features  \n",
    "**Task**: Regression (predicts continuous 1.0-5.0 stars)  \n",
    "**Features**: avg_review_stars, enhanced_parking_score, review_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2037a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"BASELINE MODEL #2: LINEAR REGRESSION\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Prepare feature matrices\n",
    "X_train_lr = train_df[BASELINE_FEATURES].fillna(0).values\n",
    "X_val_lr = val_df[BASELINE_FEATURES].fillna(0).values\n",
    "X_test_lr = test_df[BASELINE_FEATURES].fillna(0).values\n",
    "\n",
    "print(f\"\\nFeatures: {BASELINE_FEATURES}\")\n",
    "print(f\"Training shape: {X_train_lr.shape}\")\n",
    "\n",
    "# Train model\n",
    "baseline_lr = LinearRegression()\n",
    "baseline_lr.fit(X_train_lr, y_train_reg)\n",
    "\n",
    "print(\"\\nModel Coefficients:\")\n",
    "print(f\"  Intercept: {baseline_lr.intercept_:.4f}\")\n",
    "for feat, coef in zip(BASELINE_FEATURES, baseline_lr.coef_):\n",
    "    print(f\"  {feat:30s}: {coef:8.4f}\")\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred_lr = baseline_lr.predict(X_train_lr)\n",
    "y_val_pred_lr = baseline_lr.predict(X_val_lr)\n",
    "y_test_pred_lr = baseline_lr.predict(X_test_lr)\n",
    "\n",
    "# Evaluate\n",
    "train_metrics_lr = calculate_regression_metrics(y_train_reg, y_train_pred_lr, \"Training\")\n",
    "val_metrics_lr = calculate_regression_metrics(y_val_reg, y_val_pred_lr, \"Validation\")\n",
    "test_metrics_lr = calculate_regression_metrics(y_test_reg, y_test_pred_lr, \"Test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11145718",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. XGBoost Classification Model\n",
    "\n",
    "**Approach**: XGBoost with parking-focused features (leak-free)  \n",
    "**Task**: Binary Classification (predicts is_highly_rated: 0 or 1)  \n",
    "**Features**: 11 parking-related features (no rating-derived features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee1ab72",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"XGBOOST CLASSIFICATION MODEL\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Prepare classification targets\n",
    "y_train_clf = train_df[TARGET_CLASSIFICATION].values\n",
    "y_val_clf = val_df[TARGET_CLASSIFICATION].values\n",
    "y_test_clf = test_df[TARGET_CLASSIFICATION].values\n",
    "\n",
    "# Prepare feature matrices\n",
    "X_train_xgb = train_df[XGBOOST_SAFE_FEATURES].copy()\n",
    "X_val_xgb = val_df[XGBOOST_SAFE_FEATURES].copy()\n",
    "X_test_xgb = test_df[XGBOOST_SAFE_FEATURES].copy()\n",
    "\n",
    "# Convert numeric\n",
    "for col in XGBOOST_SAFE_FEATURES:\n",
    "    X_train_xgb[col] = pd.to_numeric(X_train_xgb[col], errors='coerce').fillna(0)\n",
    "    X_val_xgb[col] = pd.to_numeric(X_val_xgb[col], errors='coerce').fillna(0)\n",
    "    X_test_xgb[col] = pd.to_numeric(X_test_xgb[col], errors='coerce').fillna(0)\n",
    "\n",
    "print(f\"\\nFeatures: {len(XGBOOST_SAFE_FEATURES)} parking-related features\")\n",
    "print(f\"Training shape: {X_train_xgb.shape}\")\n",
    "\n",
    "# Calculate class imbalance\n",
    "neg = (y_train_clf == 0).sum()\n",
    "pos = (y_train_clf == 1).sum()\n",
    "scale_pos_weight = neg / max(pos, 1)\n",
    "\n",
    "print(f\"\\nClass balance:\")\n",
    "print(f\"  Negative (0): {neg:,}\")\n",
    "print(f\"  Positive (1): {pos:,}\")\n",
    "print(f\"  scale_pos_weight: {scale_pos_weight:.2f}\")\n",
    "\n",
    "# Train XGBoost\n",
    "xgb_model = XGBClassifier(\n",
    "    n_estimators=400,\n",
    "    max_depth=4,\n",
    "    learning_rate=0.05,\n",
    "    subsample=0.9,\n",
    "    colsample_bytree=0.9,\n",
    "    objective=\"binary:logistic\",\n",
    "    eval_metric=\"auc\",\n",
    "    scale_pos_weight=scale_pos_weight,\n",
    "    tree_method=\"hist\",\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(\"\\nTraining XGBoost model...\")\n",
    "xgb_model.fit(X_train_xgb, y_train_clf)\n",
    "print(\"Training complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c28d1be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "y_train_pred_xgb_proba = xgb_model.predict_proba(X_train_xgb)[:, 1]\n",
    "y_val_pred_xgb_proba = xgb_model.predict_proba(X_val_xgb)[:, 1]\n",
    "y_test_pred_xgb_proba = xgb_model.predict_proba(X_test_xgb)[:, 1]\n",
    "\n",
    "# Calculate optimal threshold using F1 score on validation set\n",
    "precision, recall, thresholds = precision_recall_curve(y_val_clf, y_val_pred_xgb_proba)\n",
    "f1_scores = []\n",
    "for t in thresholds:\n",
    "    preds = (y_val_pred_xgb_proba >= t).astype(int)\n",
    "    f1_scores.append(f1_score(y_val_clf, preds))\n",
    "\n",
    "best_threshold = thresholds[np.argmax(f1_scores)]\n",
    "print(f\"Optimal threshold (F1-based): {best_threshold:.3f}\")\n",
    "\n",
    "# Apply threshold\n",
    "y_train_pred_xgb = (y_train_pred_xgb_proba >= best_threshold).astype(int)\n",
    "y_val_pred_xgb = (y_val_pred_xgb_proba >= best_threshold).astype(int)\n",
    "y_test_pred_xgb = (y_test_pred_xgb_proba >= best_threshold).astype(int)\n",
    "\n",
    "# Calculate classification metrics\n",
    "def calculate_classification_metrics(y_true, y_pred, y_pred_proba, set_name):\n",
    "    auc_score = roc_auc_score(y_true, y_pred_proba)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    \n",
    "    # PR AUC\n",
    "    prec_vals, rec_vals, _ = precision_recall_curve(y_true, y_pred_proba)\n",
    "    pr_auc = auc(rec_vals, prec_vals)\n",
    "    \n",
    "    print(f\"\\n{set_name} Set:\")\n",
    "    print(f\"  ROC AUC:           {auc_score:.4f}\")\n",
    "    print(f\"  PR AUC:            {pr_auc:.4f}\")\n",
    "    print(f\"  F1 Score:          {f1:.4f}\")\n",
    "    print(f\"  Precision:         {precision:.4f}\")\n",
    "    print(f\"  Recall:            {recall:.4f}\")\n",
    "    \n",
    "    return {'auc': auc_score, 'pr_auc': pr_auc, 'f1': f1, 'precision': precision, 'recall': recall}\n",
    "\n",
    "print(\"\\nXGBoost Classification Metrics:\")\n",
    "print(\"=\" * 80)\n",
    "train_metrics_xgb = calculate_classification_metrics(y_train_clf, y_train_pred_xgb, y_train_pred_xgb_proba, \"Training\")\n",
    "val_metrics_xgb = calculate_classification_metrics(y_val_clf, y_val_pred_xgb, y_val_pred_xgb_proba, \"Validation\")\n",
    "test_metrics_xgb = calculate_classification_metrics(y_test_clf, y_test_pred_xgb, y_test_pred_xgb_proba, \"Test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ddc456e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "print(\"\\nTest Set Confusion Matrix:\")\n",
    "cm = confusion_matrix(y_test_clf, y_test_pred_xgb)\n",
    "print(cm)\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test_clf, y_test_pred_xgb, digits=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c16a270e",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. Model Comparison\n",
    "\n",
    "### Important Notes:\n",
    "- **Baseline models** solve a **regression** problem (predict continuous star rating 1.0-5.0)\n",
    "- **XGBoost model** solves a **classification** problem (predict binary is_highly_rated)\n",
    "- Direct metric comparison is not appropriate due to different problem types\n",
    "- We compare them conceptually and on business value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ed93e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comparison summary\n",
    "print(\"=\" * 90)\n",
    "print(\"MODEL COMPARISON SUMMARY\")\n",
    "print(\"=\" * 90)\n",
    "\n",
    "comparison_data = {\n",
    "    'Model': [\n",
    "        'Baseline #1: Heuristic',\n",
    "        'Baseline #2: Linear Regression',\n",
    "        'XGBoost Classifier'\n",
    "    ],\n",
    "    'Task': [\n",
    "        'Regression (stars)',\n",
    "        'Regression (stars)',\n",
    "        'Classification (highly_rated)'\n",
    "    ],\n",
    "    'Features': [\n",
    "        '1 (avg_review_stars)',\n",
    "        '3 (avg_review_stars, parking, reviews)',\n",
    "        '11 (parking-focused, leak-free)'\n",
    "    ],\n",
    "    'Test Performance': [\n",
    "        f\"RMSE: {test_metrics_h['rmse']:.4f}, MAE: {test_metrics_h['mae']:.4f}\",\n",
    "        f\"RMSE: {test_metrics_lr['rmse']:.4f}, MAE: {test_metrics_lr['mae']:.4f}\",\n",
    "        f\"ROC AUC: {test_metrics_xgb['auc']:.4f}, F1: {test_metrics_xgb['f1']:.4f}\"\n",
    "    ],\n",
    "    'Strengths': [\n",
    "        'Simple, interpretable, fast',\n",
    "        'Linear, interpretable, good baseline',\n",
    "        'Parking-focused, no leakage, decision support'\n",
    "    ],\n",
    "    'Use Case': [\n",
    "        'Quick estimate of expected rating',\n",
    "        'Rating prediction with parking context',\n",
    "        'Risk assessment for parking impact'\n",
    "    ]\n",
    "}\n",
    "\n",
    "comparison_df = pd.DataFrame(comparison_data)\n",
    "print(comparison_df.to_string(index=False))\n",
    "print(\"=\" * 90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f6f06e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance comparison\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"FEATURE IMPORTANCE COMPARISON\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"\\nLinear Regression Coefficients:\")\n",
    "for feat, coef in zip(BASELINE_FEATURES, baseline_lr.coef_):\n",
    "    print(f\"  {feat:35s}: {coef:8.4f}\")\n",
    "\n",
    "print(\"\\nXGBoost Feature Importance (Top 10):\")\n",
    "xgb_importance = pd.Series(\n",
    "    xgb_model.feature_importances_,\n",
    "    index=XGBOOST_SAFE_FEATURES\n",
    ").sort_values(ascending=False)\n",
    "\n",
    "for feat, imp in xgb_importance.head(10).items():\n",
    "    print(f\"  {feat:35s}: {imp:8.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1f5e700",
   "metadata": {},
   "source": [
    "---\n",
    "## 7. Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b17fcba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare baseline regression models\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Heuristic predictions\n",
    "axes[0].scatter(y_test_reg, y_test_pred_h, alpha=0.3, s=20, label='Predictions')\n",
    "axes[0].plot([1, 5], [1, 5], 'r--', lw=2, label='Perfect Prediction')\n",
    "axes[0].set_xlabel('Actual Stars')\n",
    "axes[0].set_ylabel('Predicted Stars')\n",
    "axes[0].set_title(f'Baseline #1: Heuristic\\nTest RMSE: {test_metrics_h[\"rmse\"]:.4f}')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Linear Regression predictions\n",
    "axes[1].scatter(y_test_reg, y_test_pred_lr, alpha=0.3, s=20, label='Predictions', color='orange')\n",
    "axes[1].plot([1, 5], [1, 5], 'r--', lw=2, label='Perfect Prediction')\n",
    "axes[1].set_xlabel('Actual Stars')\n",
    "axes[1].set_ylabel('Predicted Stars')\n",
    "axes[1].set_title(f'Baseline #2: Linear Regression\\nTest RMSE: {test_metrics_lr[\"rmse\"]:.4f}')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d0cedb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost visualizations\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test_clf, y_test_pred_xgb)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[0])\n",
    "axes[0].set_xlabel('Predicted')\n",
    "axes[0].set_ylabel('Actual')\n",
    "axes[0].set_title(f'XGBoost Confusion Matrix\\nTest F1: {test_metrics_xgb[\"f1\"]:.4f}')\n",
    "\n",
    "# ROC Curve visualization via probability distribution\n",
    "axes[1].hist(y_test_pred_xgb_proba[y_test_clf == 0], bins=30, alpha=0.5, label='Negative Class', color='red')\n",
    "axes[1].hist(y_test_pred_xgb_proba[y_test_clf == 1], bins=30, alpha=0.5, label='Positive Class', color='green')\n",
    "axes[1].axvline(best_threshold, linestyle='--', color='black', label=f'Threshold={best_threshold:.3f}')\n",
    "axes[1].set_xlabel('Predicted Probability')\n",
    "axes[1].set_ylabel('Count')\n",
    "axes[1].set_title(f'Probability Distribution\\nROC AUC: {test_metrics_xgb[\"auc\"]:.4f}')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "# Feature Importance\n",
    "top_features = xgb_importance.head(10)\n",
    "axes[2].barh(range(len(top_features)), top_features.values)\n",
    "axes[2].set_yticks(range(len(top_features)))\n",
    "axes[2].set_yticklabels(top_features.index, fontsize=9)\n",
    "axes[2].set_xlabel('Importance')\n",
    "axes[2].set_title('XGBoost Feature Importance (Top 10)')\n",
    "axes[2].grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50432422",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline regression metrics comparison\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Error metrics\n",
    "metrics = ['RMSE', 'MAE']\n",
    "heuristic_vals = [test_metrics_h['rmse'], test_metrics_h['mae']]\n",
    "lr_vals = [test_metrics_lr['rmse'], test_metrics_lr['mae']]\n",
    "\n",
    "x = np.arange(len(metrics))\n",
    "width = 0.35\n",
    "\n",
    "axes[0].bar(x - width/2, heuristic_vals, width, label='Heuristic', alpha=0.8, color='skyblue')\n",
    "axes[0].bar(x + width/2, lr_vals, width, label='Linear Regression', alpha=0.8, color='orange')\n",
    "axes[0].set_ylabel('Error')\n",
    "axes[0].set_title('Baseline Models: Error Metrics (Test Set)')\n",
    "axes[0].set_xticks(x)\n",
    "axes[0].set_xticklabels(metrics)\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Business metrics\n",
    "business_metrics = ['Within 0.5★', 'Within 1.0★']\n",
    "heuristic_business = [test_metrics_h['within_05'], test_metrics_h['within_10']]\n",
    "lr_business = [test_metrics_lr['within_05'], test_metrics_lr['within_10']]\n",
    "\n",
    "x2 = np.arange(len(business_metrics))\n",
    "axes[1].bar(x2 - width/2, heuristic_business, width, label='Heuristic', alpha=0.8, color='skyblue')\n",
    "axes[1].bar(x2 + width/2, lr_business, width, label='Linear Regression', alpha=0.8, color='orange')\n",
    "axes[1].set_ylabel('Percentage (%)')\n",
    "axes[1].set_title('Baseline Models: Business Metrics (Test Set)')\n",
    "axes[1].set_xticks(x2)\n",
    "axes[1].set_xticklabels(business_metrics)\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Calculate improvement\n",
    "rmse_improvement = (test_metrics_h['rmse'] - test_metrics_lr['rmse']) / test_metrics_h['rmse'] * 100\n",
    "print(f\"\\nLinear Regression improvement over Heuristic: {rmse_improvement:+.1f}% RMSE reduction\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89a5d7d9",
   "metadata": {},
   "source": [
    "---\n",
    "## 8. Key Insights & Findings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c666e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 90)\n",
    "print(\"KEY INSIGHTS & FINDINGS\")\n",
    "print(\"=\" * 90)\n",
    "\n",
    "print(\"\\n1. BASELINE REGRESSION MODELS (Star Rating Prediction)\")\n",
    "print(\"-\" * 90)\n",
    "print(f\"   Heuristic Baseline:\")\n",
    "print(f\"     - Test RMSE: {test_metrics_h['rmse']:.4f}\")\n",
    "print(f\"     - Test MAE: {test_metrics_h['mae']:.4f}\")\n",
    "print(f\"     - Uses only avg_review_stars (simplest predictor)\")\n",
    "print(f\"     - Represents consumer view: what rating shows on Yelp\")\n",
    "\n",
    "print(f\"\\n   Linear Regression Baseline:\")\n",
    "print(f\"     - Test RMSE: {test_metrics_lr['rmse']:.4f}\")\n",
    "print(f\"     - Test MAE: {test_metrics_lr['mae']:.4f}\")\n",
    "print(f\"     - Improvement over heuristic: {rmse_improvement:+.1f}% RMSE reduction\")\n",
    "print(f\"     - Incorporates parking score and review count\")\n",
    "print(f\"     - Parking coefficient: {baseline_lr.coef_[1]:.4f}\")\n",
    "\n",
    "if test_metrics_lr['rmse'] < 0.7:\n",
    "    print(\"     EXCELLENT: Baseline exceeds expectations\")\n",
    "elif test_metrics_lr['rmse'] < 0.8:\n",
    "    print(\"     GOOD: Baseline meets expectations\")\n",
    "\n",
    "print(\"\\n2. XGBOOST CLASSIFICATION MODEL (Highly Rated Prediction)\")\n",
    "print(\"-\" * 90)\n",
    "print(f\"   Performance:\")\n",
    "print(f\"     - Test ROC AUC: {test_metrics_xgb['auc']:.4f}\")\n",
    "print(f\"     - Test PR AUC: {test_metrics_xgb['pr_auc']:.4f}\")\n",
    "print(f\"     - Test F1 Score: {test_metrics_xgb['f1']:.4f}\")\n",
    "print(f\"     - Precision: {test_metrics_xgb['precision']:.4f}\")\n",
    "print(f\"     - Recall: {test_metrics_xgb['recall']:.4f}\")\n",
    "\n",
    "print(f\"\\n   Key Characteristics:\")\n",
    "print(f\"     - Uses ONLY parking-related features (no rating leakage)\")\n",
    "print(f\"     - Moderate performance (ROC AUC ~0.64) reflects true parking signal\")\n",
    "print(f\"     - Parking is meaningful but not dominant predictor\")\n",
    "print(f\"     - Designed for risk assessment, not definitive prediction\")\n",
    "\n",
    "print(f\"\\n   Most Important Parking Features:\")\n",
    "for feat, imp in xgb_importance.head(5).items():\n",
    "    print(f\"     - {feat}: {imp:.4f}\")\n",
    "\n",
    "print(\"\\n3. MODEL COMPARISON & COMPLEMENTARY ROLES\")\n",
    "print(\"-\" * 90)\n",
    "print(\"   These models solve DIFFERENT problems:\")\n",
    "print(\"\")\n",
    "print(\"   Baseline Models (Regression):\")\n",
    "print(\"     • Predict continuous star rating (1.0 - 5.0)\")\n",
    "print(\"     • Use all available features including avg_review_stars\")\n",
    "print(\"     • Goal: Accurate rating prediction\")\n",
    "print(\"     • Use case: Forecast expected rating for location\")\n",
    "print(\"\")\n",
    "print(\"   XGBoost Model (Classification):\")\n",
    "print(\"     • Predict binary outcome: highly rated or not\")\n",
    "print(\"     • Use ONLY parking features (leak-free)\")\n",
    "print(\"     • Goal: Assess parking-related risk\")\n",
    "print(\"     • Use case: Identify if parking constraints will hurt ratings\")\n",
    "print(\"\")\n",
    "print(\"   - Models are complementary, not competing\")\n",
    "print(\"   - Use baseline for overall rating prediction\")\n",
    "print(\"   - Use XGBoost for parking-specific risk assessment\")\n",
    "\n",
    "print(\"\\n4. BUSINESS VALUE & RECOMMENDATIONS\")\n",
    "print(\"-\" * 90)\n",
    "print(\"   Baseline Models:\")\n",
    "print(\"     • Deploy for general rating forecasting\")\n",
    "print(\"     • Simple and interpretable for stakeholders\")\n",
    "print(\"     • Fast inference for real-time predictions\")\n",
    "print(\"\")\n",
    "print(\"   XGBoost Model:\")\n",
    "print(\"     • Deploy for parking risk stratification\")\n",
    "print(\"     • Helps identify businesses needing parking interventions\")\n",
    "print(\"     • Supports site selection and mitigation planning\")\n",
    "print(\"     • Probabilistic outputs enable risk tiering\")\n",
    "print(\"\")\n",
    "print(\"   Combined Strategy:\")\n",
    "print(\"     1. Use baseline to forecast overall expected rating\")\n",
    "print(\"     2. Use XGBoost to assess parking-specific risk\")\n",
    "print(\"     3. Combine insights for comprehensive location evaluation\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 90)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d6a2293",
   "metadata": {},
   "source": [
    "---\n",
    "## 9. Conclusion\n",
    "\n",
    "### Model Performance Summary\n",
    "\n",
    "**Baseline Models (Regression - Star Rating Prediction)**\n",
    "- Successfully predict continuous star ratings with low error\n",
    "- Heuristic and Linear Regression provide strong baselines\n",
    "- Suitable for general rating forecasting\n",
    "\n",
    "**XGBoost Model (Classification - Highly Rated Prediction)**\n",
    "- Predicts binary outcome using only parking features\n",
    "- Moderate performance (ROC AUC ~0.64) reflects real parking signal without leakage\n",
    "- Designed for risk assessment and decision support\n",
    "- Most important features: has_good_parking, parking_availability_score\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "1. **Different Problems, Different Models**: Baseline models predict exact ratings; XGBoost assesses parking risk\n",
    "2. **Parking as Risk Factor**: XGBoost confirms parking matters, but is not the sole determinant\n",
    "3. **Complementary Deployment**: Use both model types for comprehensive business intelligence\n",
    "4. **Leak-Free Analysis**: XGBoost demonstrates parking's true impact without rating-derived features\n",
    "\n",
    "### Recommendations\n",
    "\n",
    "- Deploy baseline models for **overall rating prediction**\n",
    "- Deploy XGBoost for **parking-specific risk assessment**\n",
    "- Use combined insights for **site selection and operational planning**\n",
    "- Implement risk tiering (high/moderate/low) for stakeholder communication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1bb9b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 90)\n",
    "print(\"MODEL COMPARISON ANALYSIS COMPLETE\")\n",
    "print(\"=\" * 90)\n",
    "print(f\"Completed: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(\"\\nAll models evaluated and compared successfully\")\n",
    "print(\"Baseline models demonstrate strong regression performance\")\n",
    "print(\"XGBoost model provides parking-specific risk assessment\")\n",
    "print(\"\\nKey Results Summary:\")\n",
    "print(f\"  - Heuristic RMSE: {test_metrics_h['rmse']:.4f}\")\n",
    "print(f\"  - Linear Reg RMSE: {test_metrics_lr['rmse']:.4f}\")\n",
    "print(f\"  - XGBoost ROC AUC: {test_metrics_xgb['auc']:.4f}\")\n",
    "print(f\"  - XGBoost F1 Score: {test_metrics_xgb['f1']:.4f}\")\n",
    "print(\"\\nReady for deployment and stakeholder presentation\")\n",
    "print(\"\\nRecommendation: Use both model types for comprehensive business intelligence\")\n",
    "print(\"   - Baseline models for overall rating prediction\")\n",
    "print(\"   - XGBoost model for parking risk assessment & site selection\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a30b6a7",
   "metadata": {},
   "source": [
    "---\n",
    "## 10. Save Results to S3 (Optional)\n",
    "\n",
    "Save comparison results and metrics to S3 for future reference and reporting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e62d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create results summary\n",
    "import json\n",
    "\n",
    "results_summary = {\n",
    "    'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "    'baseline_heuristic': {\n",
    "        'model_type': 'Regression (Heuristic)',\n",
    "        'features': 1,\n",
    "        'test_rmse': float(test_metrics_h['rmse']),\n",
    "        'test_mae': float(test_metrics_h['mae']),\n",
    "        'test_r2': float(test_metrics_h['r2']),\n",
    "        'within_05_stars_pct': float(test_metrics_h['within_05']),\n",
    "        'within_10_star_pct': float(test_metrics_h['within_10'])\n",
    "    },\n",
    "    'baseline_linear_regression': {\n",
    "        'model_type': 'Regression (Linear)',\n",
    "        'features': len(BASELINE_FEATURES),\n",
    "        'feature_list': BASELINE_FEATURES,\n",
    "        'test_rmse': float(test_metrics_lr['rmse']),\n",
    "        'test_mae': float(test_metrics_lr['mae']),\n",
    "        'test_r2': float(test_metrics_lr['r2']),\n",
    "        'within_05_stars_pct': float(test_metrics_lr['within_05']),\n",
    "        'within_10_star_pct': float(test_metrics_lr['within_10']),\n",
    "        'coefficients': {\n",
    "            'intercept': float(baseline_lr.intercept_),\n",
    "            'features': {feat: float(coef) for feat, coef in zip(BASELINE_FEATURES, baseline_lr.coef_)}\n",
    "        }\n",
    "    },\n",
    "    'xgboost_classifier': {\n",
    "        'model_type': 'Classification (XGBoost)',\n",
    "        'features': len(XGBOOST_SAFE_FEATURES),\n",
    "        'feature_list': XGBOOST_SAFE_FEATURES,\n",
    "        'optimal_threshold': float(best_threshold),\n",
    "        'test_roc_auc': float(test_metrics_xgb['auc']),\n",
    "        'test_pr_auc': float(test_metrics_xgb['pr_auc']),\n",
    "        'test_f1': float(test_metrics_xgb['f1']),\n",
    "        'test_precision': float(test_metrics_xgb['precision']),\n",
    "        'test_recall': float(test_metrics_xgb['recall']),\n",
    "        'feature_importance': {\n",
    "            feat: float(imp) for feat, imp in zip(XGBOOST_SAFE_FEATURES, xgb_model.feature_importances_)\n",
    "        }\n",
    "    },\n",
    "    'comparison_insights': {\n",
    "        'lr_improvement_over_heuristic_pct': float(rmse_improvement),\n",
    "        'models_are_complementary': True,\n",
    "        'recommendation': 'Use baseline for rating prediction, XGBoost for parking risk assessment'\n",
    "    }\n",
    "}\n",
    "\n",
    "# Save locally\n",
    "results_file = 'model_comparison_results.json'\n",
    "with open(results_file, 'w') as f:\n",
    "    json.dump(results_summary, f, indent=2)\n",
    "\n",
    "print(f\"Results saved locally: {results_file}\")\n",
    "\n",
    "# Upload to S3 if in SageMaker environment\n",
    "try:\n",
    "    s3_client = boto3.client('s3')\n",
    "    s3_key = f\"{prefix}/results/model_comparison_results_{strftime('%Y%m%d_%H%M%S', gmtime())}.json\"\n",
    "    s3_client.upload_file(results_file, bucket, s3_key)\n",
    "    print(f\"Results uploaded to S3: s3://{bucket}/{s3_key}\")\n",
    "except Exception as e:\n",
    "    print(f\"WARNING: Could not upload to S3: {e}\")\n",
    "    print(\"  (This is normal if running outside SageMaker)\")\n",
    "\n",
    "# Display summary\n",
    "print(\"\\n\" + \"=\" * 90)\n",
    "print(\"RESULTS SUMMARY\")\n",
    "print(\"=\" * 90)\n",
    "print(json.dumps(results_summary, indent=2))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
