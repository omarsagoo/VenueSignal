{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comprehensive ML System Monitoring\n",
    "## AAI-540 Final Project - Module 5: Monitoring & Observability\n",
    "\n",
    "**Project Team:** [Your Team Name]\n",
    "\n",
    "**Authors:** [Team Member Names]\n",
    "\n",
    "---\n",
    "\n",
    "## Overview\n",
    "\n",
    "This notebook implements comprehensive monitoring for our ML system including:\n",
    "1. **Model Monitoring** - Track prediction quality and bias\n",
    "2. **Data Monitoring** - Detect data quality issues and distribution drift\n",
    "3. **Infrastructure Monitoring** - Monitor endpoint performance and resource utilization\n",
    "4. **CloudWatch Dashboard** - Centralized visualization of all metrics\n",
    "5. **Automated Reporting** - Generate model and data quality reports\n",
    "\n",
    "---\n",
    "\n",
    "## Table of Contents\n",
    "1. [Setup & Configuration](#setup)\n",
    "2. [Model Quality Monitoring](#model-quality)\n",
    "3. [Data Quality Monitoring](#data-quality)\n",
    "4. [Model Bias Monitoring](#model-bias)\n",
    "5. [Infrastructure Monitoring](#infrastructure)\n",
    "6. [CloudWatch Dashboard](#dashboard)\n",
    "7. [Generate Reports](#reports)\n",
    "8. [Cleanup](#cleanup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup & Configuration <a id='setup'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Install and Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.12.9\n"
     ]
    }
   ],
   "source": [
    "# Verify Python version\n",
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/sagemaker-user/.config/sagemaker/config.yaml\n",
      "✓ Libraries imported successfully\n",
      "CPU times: user 1.63 s, sys: 290 ms, total: 1.92 s\n",
      "Wall time: 1.92 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import json\n",
    "import os\n",
    "from datetime import datetime, timedelta, timezone\n",
    "from time import sleep\n",
    "\n",
    "import boto3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# AWS SDK\n",
    "import boto3\n",
    "from botocore import UNSIGNED\n",
    "from botocore.client import Config\n",
    "from botocore.exceptions import ClientError\n",
    "\n",
    "# SageMaker\n",
    "import sagemaker\n",
    "from sagemaker.feature_store.feature_group import FeatureGroup\n",
    "from sagemaker.inputs import TrainingInput\n",
    "from sagemaker.serializers import CSVSerializer, JSONSerializer\n",
    "from sagemaker.deserializers import CSVDeserializer, JSONDeserializer\n",
    "from sagemaker import get_execution_role, Session, image_uris\n",
    "from sagemaker.s3 import S3Downloader, S3Uploader\n",
    "from sagemaker.model import Model\n",
    "from sagemaker.predictor import Predictor\n",
    "\n",
    "\n",
    "# Model Monitor imports\n",
    "from sagemaker.model_monitor import (\n",
    "    DataCaptureConfig,\n",
    "    DefaultModelMonitor,\n",
    "    ModelQualityMonitor,\n",
    "    DataQualityDistributionConstraints,\n",
    "    CronExpressionGenerator\n",
    ")\n",
    "\n",
    "from sagemaker.model_monitor.dataset_format import DatasetFormat\n",
    "\n",
    "# Clarify imports for bias monitoring\n",
    "from sagemaker.clarify import (\n",
    "    BiasConfig,\n",
    "    DataConfig,\n",
    "    ModelConfig,\n",
    "    ModelPredictedLabelConfig,\n",
    "    SageMakerClarifyProcessor\n",
    ")\n",
    "from sagemaker.model_monitor import BiasAnalysisConfig, ModelBiasMonitor\n",
    "\n",
    "print(\"✓ Libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Retrieve AWS Account ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully retrieved AWS Account ID: 356396930368\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # Get AWS Account ID\n",
    "    account_id = boto3.client(\"sts\").get_caller_identity()[\"Account\"]\n",
    "    print(f\"Successfully retrieved AWS Account ID: {account_id}\")\n",
    "except Exception as e:\n",
    "    print(f\"Cannot retrieve account information: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Initialize Session and Clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AWS Region: us-east-1\n",
      "SageMaker Execution Role: arn:aws:iam::356396930368:role/LabRole\n",
      "AWS clients initialized successfully\n"
     ]
    }
   ],
   "source": [
    "# AWS Region\n",
    "REGION = \"us-east-1\"\n",
    "\n",
    "# Initialize SageMaker session\n",
    "sagemaker_session = sagemaker.Session()\n",
    "role = get_execution_role()\n",
    "\n",
    "# Initialize AWS clients\n",
    "s3_client = boto3.client(\"s3\", region_name=REGION)\n",
    "s3_resource = boto3.resource(\"s3\", region_name=REGION)\n",
    "athena_client = boto3.client(\"athena\", region_name=REGION)\n",
    "sagemaker_client = boto3.client(\"sagemaker\", region_name=REGION)\n",
    "sm_client = boto3.client(\"sagemaker\", region_name=REGION)\n",
    "cloudwatch_client = boto3.client(\"cloudwatch\", region_name=REGION)\n",
    "cw_client = boto3.client(\"cloudwatch\", region_name=REGION)\n",
    "logs_client = boto3.client(\"logs\", region_name=REGION)\n",
    "\n",
    "print(f\"AWS Region: {REGION}\")\n",
    "print(f\"SageMaker Execution Role: {role}\")\n",
    "print(f\"AWS clients initialized successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Configure S3 Paths and Prefixes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'REGION' (str)\n",
      "Stored 'account_id' (str)\n",
      "Stored 'DATA_BUCKET' (str)\n",
      "Stored 'ATHENA_BUCKET' (str)\n",
      "Stored 'FEATURE_BUCKET' (str)\n",
      "Stored 'MODEL_BUCKET' (str)\n",
      "Stored 'MONITORING_BUCKET' (str)\n",
      "Stored 'ATHENA_RESULTS_S3' (str)\n",
      "Stored 'ATHENA_DB' (str)\n",
      "================================================================================\n",
      "S3 BUCKET CONFIGURATION (Account-Specific)\n",
      "================================================================================\n",
      "AWS Account ID:     356396930368\n",
      "AWS Region:         us-east-1\n",
      "\n",
      "S3 Buckets:\n",
      "  Data Bucket:      yelp-aai540-group6-356396930368\n",
      "  Athena Bucket:    yelp-aai540-group6-athena-356396930368\n",
      "  Feature Bucket:   yelp-aai540-group6-features-356396930368\n",
      "  Model Bucket:     yelp-aai540-group6-models-356396930368\n",
      "  Monitoring:       yelp-aai540-group6-monitoring-356396930368\n",
      "\n",
      "Athena Configuration:\n",
      "  Database:         yelp\n",
      "  Results Location: s3://yelp-aai540-group6-athena-356396930368/athena-results/\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Base bucket name (shared across team)\n",
    "BASE_BUCKET_NAME = \"yelp-aai540-group6\"\n",
    "\n",
    "# Individual buckets with Account ID for each team member\n",
    "DATA_BUCKET = f\"{BASE_BUCKET_NAME}-{account_id}\"  # Raw data storage\n",
    "ATHENA_BUCKET = f\"{BASE_BUCKET_NAME}-athena-{account_id}\"  # Athena queries and results\n",
    "FEATURE_BUCKET = f\"{BASE_BUCKET_NAME}-features-{account_id}\"  # Feature store offline\n",
    "MODEL_BUCKET = f\"{BASE_BUCKET_NAME}-models-{account_id}\"  # Model artifacts\n",
    "MONITORING_BUCKET = f\"{BASE_BUCKET_NAME}-monitoring-{account_id}\"  # Monitoring data\n",
    "\n",
    "# S3 Prefixes (paths within buckets)\n",
    "RAW_DATA_PREFIX = \"yelp-dataset/json/\"\n",
    "PARQUET_PREFIX = \"yelp-dataset/parquet/\"\n",
    "ATHENA_RESULTS_PREFIX = \"athena-results/\"\n",
    "FEATURE_PREFIX = \"feature-store/\"\n",
    "MODEL_PREFIX = \"models/\"\n",
    "MONITORING_PREFIX = \"monitoring/\"\n",
    "\n",
    "# Full S3 paths\n",
    "ATHENA_RESULTS_S3 = f\"s3://{ATHENA_BUCKET}/{ATHENA_RESULTS_PREFIX}\"\n",
    "\n",
    "# Athena Database\n",
    "ATHENA_DB = \"yelp\"\n",
    "\n",
    "# Store configuration\n",
    "%store REGION\n",
    "%store account_id\n",
    "%store DATA_BUCKET\n",
    "%store ATHENA_BUCKET\n",
    "%store FEATURE_BUCKET\n",
    "%store MODEL_BUCKET\n",
    "%store MONITORING_BUCKET\n",
    "%store ATHENA_RESULTS_S3\n",
    "%store ATHENA_DB\n",
    "\n",
    "# Display configuration\n",
    "print(\"=\"*80)\n",
    "print(\"S3 BUCKET CONFIGURATION (Account-Specific)\")\n",
    "print(\"=\"*80)\n",
    "print(f\"AWS Account ID:     {account_id}\")\n",
    "print(f\"AWS Region:         {REGION}\")\n",
    "print()\n",
    "print(\"S3 Buckets:\")\n",
    "print(f\"  Data Bucket:      {DATA_BUCKET}\")\n",
    "print(f\"  Athena Bucket:    {ATHENA_BUCKET}\")\n",
    "print(f\"  Feature Bucket:   {FEATURE_BUCKET}\")\n",
    "print(f\"  Model Bucket:     {MODEL_BUCKET}\")\n",
    "print(f\"  Monitoring:       {MONITORING_BUCKET}\")\n",
    "print()\n",
    "print(\"Athena Configuration:\")\n",
    "print(f\"  Database:         {ATHENA_DB}\")\n",
    "print(f\"  Results Location: {ATHENA_RESULTS_S3}\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating S3 buckets...\n",
      "  Bucket already exists: yelp-aai540-group6-356396930368\n",
      "  Bucket already exists: yelp-aai540-group6-athena-356396930368\n",
      "  Bucket already exists: yelp-aai540-group6-features-356396930368\n",
      "  Bucket already exists: yelp-aai540-group6-models-356396930368\n",
      "  Bucket already exists: yelp-aai540-group6-monitoring-356396930368\n",
      "\n",
      " All S3 buckets are ready!\n"
     ]
    }
   ],
   "source": [
    "def create_bucket_if_not_exists(bucket_name, region=REGION):\n",
    "    \"\"\"\n",
    "    Create an S3 bucket if it doesn't already exist.\n",
    "    \n",
    "    Args:\n",
    "        bucket_name: Name of the bucket to create\n",
    "        region: AWS region for the bucket\n",
    "    \n",
    "    Returns:\n",
    "        True if bucket was created or already exists, False otherwise\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Check if bucket exists\n",
    "        s3_client.head_bucket(Bucket=bucket_name)\n",
    "        print(f\"  Bucket already exists: {bucket_name}\")\n",
    "        return True\n",
    "    except ClientError as e:\n",
    "        error_code = e.response['Error']['Code']\n",
    "        if error_code == '404':\n",
    "            # Bucket doesn't exist, create it\n",
    "            try:\n",
    "                if region == 'us-east-1':\n",
    "                    s3_client.create_bucket(Bucket=bucket_name)\n",
    "                else:\n",
    "                    s3_client.create_bucket(\n",
    "                        Bucket=bucket_name,\n",
    "                        CreateBucketConfiguration={'LocationConstraint': region}\n",
    "                    )\n",
    "                print(f\"  Created bucket: {bucket_name}\")\n",
    "                return True\n",
    "            except ClientError as create_error:\n",
    "                print(f\"  Error creating bucket {bucket_name}: {create_error}\")\n",
    "                return False\n",
    "        else:\n",
    "            print(f\"  Error checking bucket {bucket_name}: {e}\")\n",
    "            return False\n",
    "\n",
    "# Create all required buckets\n",
    "print(\"Creating S3 buckets...\")\n",
    "buckets = [\n",
    "    DATA_BUCKET,\n",
    "    ATHENA_BUCKET,\n",
    "    FEATURE_BUCKET,\n",
    "    MODEL_BUCKET,\n",
    "    MONITORING_BUCKET\n",
    "]\n",
    "\n",
    "all_success = True\n",
    "for bucket in buckets:\n",
    "    if not create_bucket_if_not_exists(bucket):\n",
    "        all_success = False\n",
    "\n",
    "if all_success:\n",
    "    print(\"\\n All S3 buckets are ready!\")\n",
    "else:\n",
    "    print(\"\\n Some buckets could not be created. Please check errors above.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Monitoring Configuration:\n",
      "  Schedule: venuesignal-monitor-356396930368\n",
      "  Output: s3://yelp-aai540-group6-monitoring-356396930368/monitoring-output\n",
      "  Reports: s3://yelp-aai540-group6-monitoring-356396930368/reports\n",
      "Stored 'monitoring_schedule_name' (str)\n",
      "Stored 'monitoring_output_path' (str)\n",
      "Stored 'monitoring_reports_path' (str)\n"
     ]
    }
   ],
   "source": [
    "# Monitoring configuration using Account ID\n",
    "monitoring_schedule_name = f\"venuesignal-monitor-{account_id}\"\n",
    "baseline_job_name = f\"venuesignal-baseline-{account_id}\"\n",
    "\n",
    "# S3 paths for monitoring data\n",
    "monitoring_output_path = f\"s3://{MONITORING_BUCKET}/monitoring-output\"\n",
    "baseline_results_path = f\"s3://{MONITORING_BUCKET}/baseline-results\"\n",
    "monitoring_reports_path = f\"s3://{MONITORING_BUCKET}/reports\"\n",
    "\n",
    "print(\"Monitoring Configuration:\")\n",
    "print(f\"  Schedule: {monitoring_schedule_name}\")\n",
    "print(f\"  Output: {monitoring_output_path}\")\n",
    "print(f\"  Reports: {monitoring_reports_path}\")\n",
    "\n",
    "%store monitoring_schedule_name\n",
    "%store monitoring_output_path\n",
    "%store monitoring_reports_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== S3 Configuration ===\n",
      "Bucket: yelp-aai540-group6-monitoring-356396930368\n",
      "Data Capture: s3://yelp-aai540-group6-monitoring-356396930368/datacapture\n",
      "Baseline: s3://yelp-aai540-group6-monitoring-356396930368/baseline/results\n",
      "Model Quality: s3://yelp-aai540-group6-monitoring-356396930368/model-quality/results\n",
      "Data Quality: s3://yelp-aai540-group6-monitoring-356396930368/data-quality/results\n",
      "Bias: s3://yelp-aai540-group6-monitoring-356396930368/bias/results\n",
      "Reports: s3://yelp-aai540-group6-monitoring-356396930368/reports\n"
     ]
    }
   ],
   "source": [
    "# Get default bucket\n",
    "bucket = MONITORING_BUCKET\n",
    "\n",
    "# TODO: Update this prefix to match your project\n",
    "project_name = \"VenueSignal - Yelp Business Rating Prediction\" \n",
    "prefix = f\"yelp-aai540-group6-monitoring-356396930368\"\n",
    "\n",
    "# Define S3 paths for monitoring\n",
    "data_capture_prefix = f\"datacapture\"\n",
    "data_capture_uri = f\"s3://{MONITORING_BUCKET}/{data_capture_prefix}\"\n",
    "\n",
    "baseline_prefix = f\"baseline\"\n",
    "baseline_data_uri = f\"s3://{MONITORING_BUCKET}/{baseline_prefix}/data\"\n",
    "baseline_results_uri = f\"s3://{MONITORING_BUCKET}/{baseline_prefix}/results\"\n",
    "\n",
    "model_quality_prefix = f\"model-quality\"\n",
    "model_quality_baseline_uri = f\"s3://{MONITORING_BUCKET}/{model_quality_prefix}/baseline\"\n",
    "model_quality_results_uri = f\"s3://{MONITORING_BUCKET}/{model_quality_prefix}/results\"\n",
    "\n",
    "data_quality_prefix = f\"data-quality\"\n",
    "data_quality_baseline_uri = f\"s3://{MONITORING_BUCKET}/{data_quality_prefix}/baseline\"\n",
    "data_quality_results_uri = f\"s3://{MONITORING_BUCKET}/{data_quality_prefix}/results\"\n",
    "\n",
    "bias_prefix = f\"bias\"\n",
    "bias_baseline_uri = f\"s3://{MONITORING_BUCKET}/{bias_prefix}/baseline\"\n",
    "bias_results_uri = f\"s3://{MONITORING_BUCKET}/{bias_prefix}/results\"\n",
    "\n",
    "reports_uri = f\"s3://{MONITORING_BUCKET}/reports\"\n",
    "\n",
    "print(\"\\n=== S3 Configuration ===\")\n",
    "print(f\"Bucket: {bucket}\")\n",
    "print(f\"Data Capture: {data_capture_uri}\")\n",
    "print(f\"Baseline: {baseline_results_uri}\")\n",
    "print(f\"Model Quality: {model_quality_results_uri}\")\n",
    "print(f\"Data Quality: {data_quality_results_uri}\")\n",
    "print(f\"Bias: {bias_results_uri}\")\n",
    "print(f\"Reports: {reports_uri}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Specify Your Endpoint Name\n",
    "\n",
    "**Important:** Replace with your actual deployed endpoint name from Module 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Endpoint 'venuesignal-endpoint-2026-02-07-11-28-53' found\n",
      "  Status: InService\n",
      "  Instance Type: Unknown\n"
     ]
    }
   ],
   "source": [
    "# TODO: Update with your actual endpoint name\n",
    "endpoint_name = \"venuesignal-endpoint-2026-02-07-11-28-53\" \n",
    "\n",
    "# Verify endpoint exists\n",
    "try:\n",
    "    response = sm_client.describe_endpoint(EndpointName=endpoint_name)\n",
    "    print(f\" Endpoint '{endpoint_name}' found\")\n",
    "    print(f\"  Status: {response['EndpointStatus']}\")\n",
    "    variant = response['ProductionVariants'][0]\n",
    "    print(f\"  Instance Type: {variant.get('CurrentInstanceType', variant.get('InstanceType', 'Unknown'))}\")\n",
    "except Exception as e:\n",
    "    print(f\" Error: Endpoint '{endpoint_name}' not found\")\n",
    "    print(f\"  {str(e)}\")\n",
    "    print(\"\\nPlease update the endpoint_name variable with your deployed endpoint.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 Load Baseline Training Data\n",
    "\n",
    "**Important:** Update the path to your training data used in Module 3-4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data: s3://yelp-aai540-group6-features-356396930368/training-data/train.csv\n",
      "Validation data: s3://yelp-aai540-group6-features-356396930368/training-data/validation.csv\n",
      "\n",
      "✓ Training data loaded successfully\n",
      "  Shape: (5, 34)\n",
      "  Columns: ['review_id', 'business_id', 'user_id', 'mentions_parking', 'parking_positive', 'parking_negative', 'parking_type_lot', 'parking_type_street', 'parking_type_garage', 'parking_type_valet', 'parking_free', 'parking_paid', 'enhanced_parking_score', 'business_stars', 'business_review_count', 'avg_review_stars', 'std_review_stars', 'total_reviews', 'avg_engagement', 'pct_highly_rated', 'has_parking_data', 'parking_sentiment', 'review_stars', 'useful', 'funny', 'cool', 'engagement_score', 'is_engaged', 'review_year', 'review_month', 'review_quarter', 'is_restaurant', 'price_range_numeric', 'is_highly_rated']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>business_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>mentions_parking</th>\n",
       "      <th>parking_positive</th>\n",
       "      <th>parking_negative</th>\n",
       "      <th>parking_type_lot</th>\n",
       "      <th>parking_type_street</th>\n",
       "      <th>parking_type_garage</th>\n",
       "      <th>parking_type_valet</th>\n",
       "      <th>...</th>\n",
       "      <th>funny</th>\n",
       "      <th>cool</th>\n",
       "      <th>engagement_score</th>\n",
       "      <th>is_engaged</th>\n",
       "      <th>review_year</th>\n",
       "      <th>review_month</th>\n",
       "      <th>review_quarter</th>\n",
       "      <th>is_restaurant</th>\n",
       "      <th>price_range_numeric</th>\n",
       "      <th>is_highly_rated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ILUkOqiOI4OAP66sFIK2wg</td>\n",
       "      <td>vl40Oa75v42jvJsHwpCGKA</td>\n",
       "      <td>N0zPkywxRWcdwIdDydRjsg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2018</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>xZsG5iSqG09rMWAG5xbAuA</td>\n",
       "      <td>vl40Oa75v42jvJsHwpCGKA</td>\n",
       "      <td>awc2ZDTlv_UwVj-O0PDVLQ</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2019</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sh_k6lShYktzcDQldXEkDA</td>\n",
       "      <td>vl40Oa75v42jvJsHwpCGKA</td>\n",
       "      <td>EUL1aKj4hhBqfPhSmJ7tbQ</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2019</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>N1qv_f2jQ3L1KQswNCjlmQ</td>\n",
       "      <td>vl40Oa75v42jvJsHwpCGKA</td>\n",
       "      <td>Sx0atJz9G3Q84-dUlfnVTg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2019</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5iMBUIkxxzHJzTp1lvUOug</td>\n",
       "      <td>vl40Oa75v42jvJsHwpCGKA</td>\n",
       "      <td>6l8Pr2n0Sq2HHsHB2XyoNw</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2018</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                review_id             business_id                 user_id  \\\n",
       "0  ILUkOqiOI4OAP66sFIK2wg  vl40Oa75v42jvJsHwpCGKA  N0zPkywxRWcdwIdDydRjsg   \n",
       "1  xZsG5iSqG09rMWAG5xbAuA  vl40Oa75v42jvJsHwpCGKA  awc2ZDTlv_UwVj-O0PDVLQ   \n",
       "2  Sh_k6lShYktzcDQldXEkDA  vl40Oa75v42jvJsHwpCGKA  EUL1aKj4hhBqfPhSmJ7tbQ   \n",
       "3  N1qv_f2jQ3L1KQswNCjlmQ  vl40Oa75v42jvJsHwpCGKA  Sx0atJz9G3Q84-dUlfnVTg   \n",
       "4  5iMBUIkxxzHJzTp1lvUOug  vl40Oa75v42jvJsHwpCGKA  6l8Pr2n0Sq2HHsHB2XyoNw   \n",
       "\n",
       "   mentions_parking  parking_positive  parking_negative  parking_type_lot  \\\n",
       "0                 0                 0                 0                 0   \n",
       "1                 0                 0                 0                 0   \n",
       "2                 0                 0                 0                 0   \n",
       "3                 0                 0                 0                 0   \n",
       "4                 0                 0                 0                 0   \n",
       "\n",
       "   parking_type_street  parking_type_garage  parking_type_valet  ...  funny  \\\n",
       "0                    0                    0                   0  ...      0   \n",
       "1                    0                    0                   0  ...      0   \n",
       "2                    0                    0                   0  ...      0   \n",
       "3                    0                    0                   0  ...      0   \n",
       "4                    0                    0                   0  ...      0   \n",
       "\n",
       "   cool  engagement_score  is_engaged  review_year  review_month  \\\n",
       "0     1                 3           1         2018            12   \n",
       "1     0                 0           0         2019             8   \n",
       "2     0                 0           0         2019             3   \n",
       "3     1                 2           1         2019             9   \n",
       "4     1                 2           1         2018             9   \n",
       "\n",
       "   review_quarter  is_restaurant  price_range_numeric  is_highly_rated  \n",
       "0               4              1                    2                1  \n",
       "1               3              1                    2                1  \n",
       "2               1              1                    2                1  \n",
       "3               3              1                    2                1  \n",
       "4               3              1                    2                1  \n",
       "\n",
       "[5 rows x 34 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TODO: Update with your actual training data path\n",
    "training_data_uri = f\"s3://{FEATURE_BUCKET}/training-data/train.csv\" \n",
    "\n",
    "# TODO: Update with your actual validation/test data path for ground truth\n",
    "validation_data_uri = f\"s3://{FEATURE_BUCKET}/training-data/validation.csv\"  \n",
    "\n",
    "print(f\"Training data: {training_data_uri}\")\n",
    "print(f\"Validation data: {validation_data_uri}\")\n",
    "\n",
    "# Load a sample to verify\n",
    "try:\n",
    "    # Download a sample\n",
    "    local_training_file = S3Downloader.download(training_data_uri, \".\")\n",
    "    df_train_sample = pd.read_csv(local_training_file[0], nrows=5)\n",
    "    print(f\"\\n✓ Training data loaded successfully\")\n",
    "    print(f\"  Shape: {df_train_sample.shape}\")\n",
    "    print(f\"  Columns: {list(df_train_sample.columns)}\")\n",
    "    display(df_train_sample.head())\n",
    "except Exception as e:\n",
    "    print(f\"✗ Error loading training data: {e}\")\n",
    "    print(\"Please update the training_data_uri variable.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Model Quality Monitoring <a id='model-quality'></a>\n",
    "\n",
    "Model Quality Monitoring tracks the prediction accuracy of your model over time by comparing predictions against ground truth labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Create Model Quality Baseline\n",
    "\n",
    "First, we need to establish a baseline for model quality metrics using our validation dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem Type: BinaryClassification\n",
      "Inference Attribute: prediction\n",
      "Ground Truth Attribute: label\n"
     ]
    }
   ],
   "source": [
    "# TODO: Specify your problem type\n",
    "problem_type = \"BinaryClassification\"  # Options: \"BinaryClassification\", \"MulticlassClassification\", \"Regression\"\n",
    "\n",
    "# TODO: Specify inference and ground truth column names\n",
    "inference_attribute = \"prediction\"  # Column name for predictions in captured data\n",
    "probability_attribute = \"probability\"  # Column name for probability scores (if applicable)\n",
    "ground_truth_attribute = \"label\"  # Column name for actual labels in ground truth data\n",
    "\n",
    "print(f\"Problem Type: {problem_type}\")\n",
    "print(f\"Inference Attribute: {inference_attribute}\")\n",
    "print(f\"Ground Truth Attribute: {ground_truth_attribute}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Model Quality Monitor initialized\n",
      "CPU times: user 21.7 ms, sys: 253 μs, total: 22 ms\n",
      "Wall time: 21.6 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Initialize Model Quality Monitor\n",
    "model_quality_monitor = ModelQualityMonitor(\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.m5.xlarge\",  # Resource-efficient instance\n",
    "    volume_size_in_gb=20,\n",
    "    max_runtime_in_seconds=1800,\n",
    "    sagemaker_session=sagemaker_session,\n",
    ")\n",
    "\n",
    "print(\"✓ Model Quality Monitor initialized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating processing-job with name baseline-suggestion-job-2026-02-08-10-35-23-576\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...........................................................* Error creating baseline: Error for Processing job baseline-suggestion-job-2026-02-08-10-35-23-576: Failed. Reason: AlgorithmError: Error: Errors occurred when analyzing your data. Please check CloudWatch logs for more details., exit code: 255. Check troubleshooting guide for common errors: https://docs.aws.amazon.com/sagemaker/latest/dg/sagemaker-python-sdk-troubleshooting.html\n",
      "This may happen if your validation data format doesn't match expectations.\n",
      "Verify that your validation data has both predictions and ground truth labels.\n",
      "CPU times: user 216 ms, sys: 18.7 ms, total: 235 ms\n",
      "Wall time: 5min 2s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Suggest baseline for model quality\n",
    "try:\n",
    "    model_quality_monitor.suggest_baseline(\n",
    "        baseline_dataset=validation_data_uri,\n",
    "        dataset_format=DatasetFormat.csv(header=True),\n",
    "        output_s3_uri=model_quality_baseline_uri,\n",
    "        problem_type=problem_type,\n",
    "        inference_attribute=inference_attribute,\n",
    "        ground_truth_attribute=ground_truth_attribute,\n",
    "        wait=True,\n",
    "        logs=False\n",
    "    )\n",
    "    print(\" Model quality baseline created successfully\")\n",
    "except Exception as e:\n",
    "    print(f\" Error creating baseline: {e}\")\n",
    "    print(\"This may happen if your validation data format doesn't match expectations.\")\n",
    "    print(\"Verify that your validation data has both predictions and ground truth labels.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Review Model Quality Baseline Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #ff0000; text-decoration-color: #ff0000\">╭─────────────────────────────── </span><span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">Traceback </span><span style=\"color: #ff7f7f; text-decoration-color: #ff7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #ff0000; text-decoration-color: #ff0000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span> in &lt;module&gt;:3                                                                                    <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>                                                                                                  <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 # Download and display baseline statistics</span>                                                  <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2 </span>baseline_job = model_quality_monitor.latest_baselining_job                                  <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 3 baseline_stats_uri = <span style=\"font-weight: bold; text-decoration: underline\">baseline_job.baseline_statistics</span>().statistics_s3_uri                   <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 4 </span>                                                                                            <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 5 </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">print</span>(<span style=\"color: #808000; text-decoration-color: #808000\">f\"Baseline Statistics URI: {</span>baseline_stats_uri<span style=\"color: #808000; text-decoration-color: #808000\">}\"</span>)                                     <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 6 </span>                                                                                            <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">AttributeError: </span><span style=\"color: #008700; text-decoration-color: #008700\">'NoneType'</span> object has no attribute <span style=\"color: #008700; text-decoration-color: #008700\">'baseline_statistics'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[38;2;255;0;0m╭─\u001b[0m\u001b[38;2;255;0;0m──────────────────────────────\u001b[0m\u001b[38;2;255;0;0m \u001b[0m\u001b[1;38;2;255;0;0mTraceback \u001b[0m\u001b[1;2;38;2;255;0;0m(most recent call last)\u001b[0m\u001b[38;2;255;0;0m \u001b[0m\u001b[38;2;255;0;0m───────────────────────────────\u001b[0m\u001b[38;2;255;0;0m─╮\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m in <module>:3                                                                                    \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m                                                                                                  \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m 1 \u001b[0m\u001b[2m# Download and display baseline statistics\u001b[0m                                                  \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m 2 \u001b[0mbaseline_job = model_quality_monitor.latest_baselining_job                                  \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m \u001b[31m❱ \u001b[0m 3 baseline_stats_uri = \u001b[1;4mbaseline_job.baseline_statistics\u001b[0m().statistics_s3_uri                   \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m 4 \u001b[0m                                                                                            \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m 5 \u001b[0m\u001b[96mprint\u001b[0m(\u001b[33mf\u001b[0m\u001b[33m\"\u001b[0m\u001b[33mBaseline Statistics URI: \u001b[0m\u001b[33m{\u001b[0mbaseline_stats_uri\u001b[33m}\u001b[0m\u001b[33m\"\u001b[0m)                                     \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m 6 \u001b[0m                                                                                            \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mAttributeError: \u001b[0m\u001b[38;2;0;135;0m'NoneType'\u001b[0m object has no attribute \u001b[38;2;0;135;0m'baseline_statistics'\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Download and display baseline statistics\n",
    "baseline_job = model_quality_monitor.latest_baselining_job\n",
    "baseline_stats_uri = baseline_job.baseline_statistics().statistics_s3_uri\n",
    "\n",
    "print(f\"Baseline Statistics URI: {baseline_stats_uri}\")\n",
    "\n",
    "# Download the baseline statistics\n",
    "local_stats_file = S3Downloader.download(baseline_stats_uri, \".\")\n",
    "with open(local_stats_file[0], 'r') as f:\n",
    "    baseline_stats = json.load(f)\n",
    "\n",
    "print(\"\\n=== Model Quality Baseline Metrics ===\")\n",
    "if 'binary_classification_metrics' in baseline_stats:\n",
    "    metrics = baseline_stats['binary_classification_metrics']\n",
    "    for metric, value in metrics.items():\n",
    "        print(f\"{metric}: {value['value']:.4f}\")\n",
    "elif 'regression_metrics' in baseline_stats:\n",
    "    metrics = baseline_stats['regression_metrics']\n",
    "    for metric, value in metrics.items():\n",
    "        print(f\"{metric}: {value['value']:.4f}\")\n",
    "else:\n",
    "    print(json.dumps(baseline_stats, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Create Model Quality Monitoring Schedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from sagemaker.model_monitor import CronExpressionGenerator\n",
    "\n",
    "model_quality_schedule_name = f\"{project_name}-model-quality-schedule-{datetime.now(timezone.utc):%Y%m%d-%H%M}\"\n",
    "\n",
    "try:\n",
    "    model_quality_monitor.create_monitoring_schedule(\n",
    "        monitor_schedule_name=model_quality_schedule_name,\n",
    "        endpoint_input=endpoint_name,\n",
    "        output_s3_uri=model_quality_results_uri,\n",
    "        problem_type=problem_type,\n",
    "        ground_truth_input=validation_data_uri,  # You'll need to update this with actual ground truth source\n",
    "        constraints=model_quality_monitor.suggested_constraints(),\n",
    "        schedule_cron_expression=CronExpressionGenerator.daily(),  # Run daily to save costs\n",
    "        enable_cloudwatch_metrics=True,\n",
    "    )\n",
    "    print(f\"✓ Model quality monitoring schedule created: {model_quality_schedule_name}\")\n",
    "except Exception as e:\n",
    "    print(f\"✗ Error creating schedule: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Quality Monitoring <a id='data-quality'></a>\n",
    "\n",
    "Data Quality Monitoring detects anomalies and data drift in the input features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Enable Data Capture on Endpoint\n",
    "\n",
    "**Note:** If you already have data capture enabled from Module 4, you can skip this step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if data capture is already enabled\n",
    "try:\n",
    "    endpoint_config = sm_client.describe_endpoint(EndpointName=endpoint_name)\n",
    "    config_name = endpoint_config['EndpointConfigName']\n",
    "    config_details = sm_client.describe_endpoint_config(EndpointConfigName=config_name)\n",
    "    \n",
    "    if 'DataCaptureConfig' in config_details:\n",
    "        print(\"✓ Data capture is already enabled on this endpoint\")\n",
    "        capture_enabled = True\n",
    "    else:\n",
    "        print(\"✗ Data capture is not enabled\")\n",
    "        print(\"You need to update your endpoint config to enable data capture.\")\n",
    "        print(\"See the code below for reference.\")\n",
    "        capture_enabled = False\n",
    "except Exception as e:\n",
    "    print(f\"Error checking endpoint: {e}\")\n",
    "    capture_enabled = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If data capture is not enabled, use this code to update your endpoint\n",
    "# Uncomment and run if needed\n",
    "\n",
    "# from sagemaker.model_monitor import DataCaptureConfig\n",
    "# \n",
    "# data_capture_config = DataCaptureConfig(\n",
    "#     enable_capture=True,\n",
    "#     sampling_percentage=100,  # Capture 100% of requests (reduce for high-traffic endpoints)\n",
    "#     destination_s3_uri=data_capture_uri,\n",
    "#     capture_options=[\"INPUT\", \"OUTPUT\"]  # Capture both input and output\n",
    "# )\n",
    "# \n",
    "# # You'll need to update your endpoint configuration\n",
    "# # This requires redeploying the endpoint with the new configuration\n",
    "# # See Module 4 deployment code for reference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Create Data Quality Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Initialize Data Quality Monitor\n",
    "data_quality_monitor = DefaultModelMonitor(\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.m5.xlarge\",\n",
    "    volume_size_in_gb=20,\n",
    "    max_runtime_in_seconds=1800,\n",
    "    sagemaker_session=sagemaker_session,\n",
    ")\n",
    "\n",
    "print(\"✓ Data Quality Monitor initialized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Create baseline for data quality\n",
    "try:\n",
    "    data_quality_monitor.suggest_baseline(\n",
    "        baseline_dataset=training_data_uri,\n",
    "        dataset_format=DatasetFormat.csv(header=True),\n",
    "        output_s3_uri=data_quality_baseline_uri,\n",
    "        wait=True,\n",
    "        logs=False\n",
    "    )\n",
    "    print(\"✓ Data quality baseline created successfully\")\n",
    "except Exception as e:\n",
    "    print(f\"✗ Error creating baseline: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Review Data Quality Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download and display baseline statistics\n",
    "baseline_job = data_quality_monitor.latest_baselining_job\n",
    "schema_uri = baseline_job.baseline_statistics().statistics_s3_uri\n",
    "constraints_uri = baseline_job.suggested_constraints().constraints_s3_uri\n",
    "\n",
    "print(f\"Schema URI: {schema_uri}\")\n",
    "print(f\"Constraints URI: {constraints_uri}\")\n",
    "\n",
    "# Download statistics\n",
    "local_stats_file = S3Downloader.download(schema_uri, \".\")\n",
    "with open(local_stats_file[0], 'r') as f:\n",
    "    data_stats = json.load(f)\n",
    "\n",
    "print(\"\\n=== Data Quality Statistics (Sample) ===\")\n",
    "if 'features' in data_stats:\n",
    "    for i, feature in enumerate(list(data_stats['features'])[:5]):  # Show first 5 features\n",
    "        print(f\"\\nFeature: {feature['name']}\")\n",
    "        print(f\"  Type: {feature.get('inferred_type', 'unknown')}\")\n",
    "        if 'numerical_statistics' in feature:\n",
    "            stats = feature['numerical_statistics']\n",
    "            print(f\"  Min: {stats.get('min', 'N/A')}\")\n",
    "            print(f\"  Max: {stats.get('max', 'N/A')}\")\n",
    "            print(f\"  Mean: {stats.get('mean', 'N/A')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Create Data Quality Monitoring Schedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "data_quality_schedule_name = f\"{project_name}-data-quality-schedule-{datetime.now(timezone.utc):%Y%m%d-%H%M}\"\n",
    "\n",
    "try:\n",
    "    data_quality_monitor.create_monitoring_schedule(\n",
    "        monitor_schedule_name=data_quality_schedule_name,\n",
    "        endpoint_input=endpoint_name,\n",
    "        output_s3_uri=data_quality_results_uri,\n",
    "        statistics=data_quality_monitor.baseline_statistics(),\n",
    "        constraints=data_quality_monitor.suggested_constraints(),\n",
    "        schedule_cron_expression=CronExpressionGenerator.daily(),\n",
    "        enable_cloudwatch_metrics=True,\n",
    "    )\n",
    "    print(f\"✓ Data quality monitoring schedule created: {data_quality_schedule_name}\")\n",
    "except Exception as e:\n",
    "    print(f\"✗ Error creating schedule: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model Bias Monitoring <a id='model-bias'></a>\n",
    "\n",
    "**Note:** Bias monitoring is optional but recommended if your model uses sensitive attributes. Skip this section if not applicable to your project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Configure Bias Monitoring (Optional)\n",
    "\n",
    "Uncomment and configure if your dataset has sensitive attributes to monitor for bias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # TODO: Configure if applicable to your project\n",
    "# \n",
    "# # Specify the sensitive attribute (facet) to monitor\n",
    "# facet_name = \"age_group\"  # UPDATE THIS - e.g., \"gender\", \"age\", \"ethnicity\"\n",
    "# facet_values_or_threshold = [1]  # UPDATE THIS - sensitive group(s) to monitor\n",
    "# \n",
    "# # Label column name\n",
    "# label_name = \"label\"  # UPDATE THIS\n",
    "# \n",
    "# # Configure bias\n",
    "# bias_config = BiasConfig(\n",
    "#     label_values_or_threshold=[1],  # Positive class\n",
    "#     facet_name=facet_name,\n",
    "#     facet_values_or_threshold=facet_values_or_threshold,\n",
    "# )\n",
    "# \n",
    "# print(f\"Bias monitoring configured for facet: {facet_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Infrastructure Monitoring <a id='infrastructure'></a>\n",
    "\n",
    "Monitor endpoint performance, latency, and resource utilization using CloudWatch metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Create CloudWatch Alarms for Endpoint Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define alarm thresholds\n",
    "LATENCY_THRESHOLD_MS = 1000  # Alert if p99 latency > 1 second\n",
    "ERROR_RATE_THRESHOLD = 5  # Alert if error rate > 5%\n",
    "CPU_THRESHOLD = 80  # Alert if CPU > 80%\n",
    "MEMORY_THRESHOLD = 80  # Alert if memory > 80%\n",
    "\n",
    "print(\"Alarm Thresholds:\")\n",
    "print(f\"  Latency: {LATENCY_THRESHOLD_MS}ms\")\n",
    "print(f\"  Error Rate: {ERROR_RATE_THRESHOLD}%\")\n",
    "print(f\"  CPU: {CPU_THRESHOLD}%\")\n",
    "print(f\"  Memory: {MEMORY_THRESHOLD}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get endpoint variant name\n",
    "endpoint_desc = sm_client.describe_endpoint(EndpointName=endpoint_name)\n",
    "variant_name = endpoint_desc['ProductionVariants'][0]['VariantName']\n",
    "\n",
    "print(f\"Endpoint: {endpoint_name}\")\n",
    "print(f\"Variant: {variant_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Model Latency Alarm\n",
    "try:\n",
    "    cw_client.put_metric_alarm(\n",
    "        AlarmName=f\"{endpoint_name}-High-Latency\",\n",
    "        ComparisonOperator='GreaterThanThreshold',\n",
    "        EvaluationPeriods=2,\n",
    "        MetricName='ModelLatency',\n",
    "        Namespace='AWS/SageMaker',\n",
    "        Period=300,  # 5 minutes\n",
    "        Statistic='Average',\n",
    "        Threshold=LATENCY_THRESHOLD_MS * 1000,  # Convert to microseconds\n",
    "        ActionsEnabled=False,\n",
    "        AlarmDescription='Alert when model latency is too high',\n",
    "        Dimensions=[\n",
    "            {'Name': 'EndpointName', 'Value': endpoint_name},\n",
    "            {'Name': 'VariantName', 'Value': variant_name}\n",
    "        ]\n",
    "    )\n",
    "    print(\"✓ Created alarm: High Latency\")\n",
    "except Exception as e:\n",
    "    print(f\"✗ Error creating latency alarm: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Model Invocation Error Rate Alarm\n",
    "try:\n",
    "    cw_client.put_metric_alarm(\n",
    "        AlarmName=f\"{endpoint_name}-High-Error-Rate\",\n",
    "        ComparisonOperator='GreaterThanThreshold',\n",
    "        EvaluationPeriods=2,\n",
    "        Metrics=[\n",
    "            {\n",
    "                'Id': 'error_rate',\n",
    "                'Expression': '(m2/m1)*100',\n",
    "                'Label': 'Error Rate (%)',\n",
    "            },\n",
    "            {\n",
    "                'Id': 'm1',\n",
    "                'MetricStat': {\n",
    "                    'Metric': {\n",
    "                        'Namespace': 'AWS/SageMaker',\n",
    "                        'MetricName': 'Invocations',\n",
    "                        'Dimensions': [\n",
    "                            {'Name': 'EndpointName', 'Value': endpoint_name},\n",
    "                            {'Name': 'VariantName', 'Value': variant_name}\n",
    "                        ]\n",
    "                    },\n",
    "                    'Period': 300,\n",
    "                    'Stat': 'Sum',\n",
    "                },\n",
    "                'ReturnData': False,\n",
    "            },\n",
    "            {\n",
    "                'Id': 'm2',\n",
    "                'MetricStat': {\n",
    "                    'Metric': {\n",
    "                        'Namespace': 'AWS/SageMaker',\n",
    "                        'MetricName': 'ModelInvocationErrors',\n",
    "                        'Dimensions': [\n",
    "                            {'Name': 'EndpointName', 'Value': endpoint_name},\n",
    "                            {'Name': 'VariantName', 'Value': variant_name}\n",
    "                        ]\n",
    "                    },\n",
    "                    'Period': 300,\n",
    "                    'Stat': 'Sum',\n",
    "                },\n",
    "                'ReturnData': False,\n",
    "            },\n",
    "        ],\n",
    "        Threshold=ERROR_RATE_THRESHOLD,\n",
    "        ActionsEnabled=False,\n",
    "        AlarmDescription='Alert when error rate exceeds threshold'\n",
    "    )\n",
    "    print(\"✓ Created alarm: High Error Rate\")\n",
    "except Exception as e:\n",
    "    print(f\"✗ Error creating error rate alarm: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create CPU Utilization Alarm\n",
    "try:\n",
    "    cw_client.put_metric_alarm(\n",
    "        AlarmName=f\"{endpoint_name}-High-CPU\",\n",
    "        ComparisonOperator='GreaterThanThreshold',\n",
    "        EvaluationPeriods=2,\n",
    "        MetricName='CPUUtilization',\n",
    "        Namespace='/aws/sagemaker/Endpoints',\n",
    "        Period=300,\n",
    "        Statistic='Average',\n",
    "        Threshold=CPU_THRESHOLD,\n",
    "        ActionsEnabled=False,\n",
    "        AlarmDescription='Alert when CPU utilization is high',\n",
    "        Dimensions=[\n",
    "            {'Name': 'EndpointName', 'Value': endpoint_name},\n",
    "            {'Name': 'VariantName', 'Value': variant_name}\n",
    "        ]\n",
    "    )\n",
    "    print(\"✓ Created alarm: High CPU\")\n",
    "except Exception as e:\n",
    "    print(f\"✗ Error creating CPU alarm: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Memory Utilization Alarm\n",
    "try:\n",
    "    cw_client.put_metric_alarm(\n",
    "        AlarmName=f\"{endpoint_name}-High-Memory\",\n",
    "        ComparisonOperator='GreaterThanThreshold',\n",
    "        EvaluationPeriods=2,\n",
    "        MetricName='MemoryUtilization',\n",
    "        Namespace='/aws/sagemaker/Endpoints',\n",
    "        Period=300,\n",
    "        Statistic='Average',\n",
    "        Threshold=MEMORY_THRESHOLD,\n",
    "        ActionsEnabled=False,\n",
    "        AlarmDescription='Alert when memory utilization is high',\n",
    "        Dimensions=[\n",
    "            {'Name': 'EndpointName', 'Value': endpoint_name},\n",
    "            {'Name': 'VariantName', 'Value': variant_name}\n",
    "        ]\n",
    "    )\n",
    "    print(\"✓ Created alarm: High Memory\")\n",
    "except Exception as e:\n",
    "    print(f\"✗ Error creating memory alarm: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 List All CloudWatch Alarms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all alarms for this endpoint\n",
    "alarms = cw_client.describe_alarms(\n",
    "    AlarmNamePrefix=endpoint_name\n",
    ")\n",
    "\n",
    "print(\"\\n=== CloudWatch Alarms ===\")\n",
    "for alarm in alarms['MetricAlarms']:\n",
    "    print(f\"\\n{alarm['AlarmName']}\")\n",
    "    print(f\"  State: {alarm['StateValue']}\")\n",
    "    print(f\"  Metric: {alarm.get('MetricName', 'Expression')}\")\n",
    "    print(f\"  Threshold: {alarm['Threshold']}\")\n",
    "    print(f\"  Description: {alarm.get('AlarmDescription', 'N/A')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. CloudWatch Dashboard <a id='dashboard'></a>\n",
    "\n",
    "Create a centralized dashboard for visualizing all monitoring metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 Create Comprehensive Monitoring Dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dashboard_name = f\"{project_name}-monitoring-dashboard\"\n",
    "\n",
    "# Define dashboard body\n",
    "dashboard_body = {\n",
    "    \"widgets\": [\n",
    "        # Row 1: Endpoint Performance\n",
    "        {\n",
    "            \"type\": \"metric\",\n",
    "            \"properties\": {\n",
    "                \"metrics\": [\n",
    "                    [\"AWS/SageMaker\", \"ModelLatency\", {\"stat\": \"Average\", \"label\": \"Avg Latency\"}],\n",
    "                    [\"...\", {\"stat\": \"p99\", \"label\": \"P99 Latency\"}]\n",
    "                ],\n",
    "                \"period\": 300,\n",
    "                \"stat\": \"Average\",\n",
    "                \"region\": region,\n",
    "                \"title\": \"Model Latency (microseconds)\",\n",
    "                \"dimensions\": {\n",
    "                    \"EndpointName\": endpoint_name,\n",
    "                    \"VariantName\": variant_name\n",
    "                },\n",
    "                \"yAxis\": {\"left\": {\"min\": 0}}\n",
    "            },\n",
    "            \"width\": 12,\n",
    "            \"height\": 6,\n",
    "            \"x\": 0,\n",
    "            \"y\": 0\n",
    "        },\n",
    "        {\n",
    "            \"type\": \"metric\",\n",
    "            \"properties\": {\n",
    "                \"metrics\": [\n",
    "                    [\"AWS/SageMaker\", \"Invocations\", {\"stat\": \"Sum\", \"label\": \"Total Invocations\"}],\n",
    "                    [\".\", \"ModelInvocationErrors\", {\"stat\": \"Sum\", \"label\": \"Errors\"}]\n",
    "                ],\n",
    "                \"period\": 300,\n",
    "                \"stat\": \"Sum\",\n",
    "                \"region\": region,\n",
    "                \"title\": \"Invocations & Errors\",\n",
    "                \"dimensions\": {\n",
    "                    \"EndpointName\": endpoint_name,\n",
    "                    \"VariantName\": variant_name\n",
    "                },\n",
    "                \"yAxis\": {\"left\": {\"min\": 0}}\n",
    "            },\n",
    "            \"width\": 12,\n",
    "            \"height\": 6,\n",
    "            \"x\": 12,\n",
    "            \"y\": 0\n",
    "        },\n",
    "        \n",
    "        # Row 2: Resource Utilization\n",
    "        {\n",
    "            \"type\": \"metric\",\n",
    "            \"properties\": {\n",
    "                \"metrics\": [\n",
    "                    [\"/aws/sagemaker/Endpoints\", \"CPUUtilization\", {\"stat\": \"Average\"}]\n",
    "                ],\n",
    "                \"period\": 300,\n",
    "                \"stat\": \"Average\",\n",
    "                \"region\": region,\n",
    "                \"title\": \"CPU Utilization (%)\",\n",
    "                \"dimensions\": {\n",
    "                    \"EndpointName\": endpoint_name,\n",
    "                    \"VariantName\": variant_name\n",
    "                },\n",
    "                \"yAxis\": {\"left\": {\"min\": 0, \"max\": 100}}\n",
    "            },\n",
    "            \"width\": 12,\n",
    "            \"height\": 6,\n",
    "            \"x\": 0,\n",
    "            \"y\": 6\n",
    "        },\n",
    "        {\n",
    "            \"type\": \"metric\",\n",
    "            \"properties\": {\n",
    "                \"metrics\": [\n",
    "                    [\"/aws/sagemaker/Endpoints\", \"MemoryUtilization\", {\"stat\": \"Average\"}]\n",
    "                ],\n",
    "                \"period\": 300,\n",
    "                \"stat\": \"Average\",\n",
    "                \"region\": region,\n",
    "                \"title\": \"Memory Utilization (%)\",\n",
    "                \"dimensions\": {\n",
    "                    \"EndpointName\": endpoint_name,\n",
    "                    \"VariantName\": variant_name\n",
    "                },\n",
    "                \"yAxis\": {\"left\": {\"min\": 0, \"max\": 100}}\n",
    "            },\n",
    "            \"width\": 12,\n",
    "            \"height\": 6,\n",
    "            \"x\": 12,\n",
    "            \"y\": 6\n",
    "        },\n",
    "        \n",
    "        # Row 3: Disk Utilization\n",
    "        {\n",
    "            \"type\": \"metric\",\n",
    "            \"properties\": {\n",
    "                \"metrics\": [\n",
    "                    [\"/aws/sagemaker/Endpoints\", \"DiskUtilization\", {\"stat\": \"Average\"}]\n",
    "                ],\n",
    "                \"period\": 300,\n",
    "                \"stat\": \"Average\",\n",
    "                \"region\": region,\n",
    "                \"title\": \"Disk Utilization (%)\",\n",
    "                \"dimensions\": {\n",
    "                    \"EndpointName\": endpoint_name,\n",
    "                    \"VariantName\": variant_name\n",
    "                },\n",
    "                \"yAxis\": {\"left\": {\"min\": 0, \"max\": 100}}\n",
    "            },\n",
    "            \"width\": 12,\n",
    "            \"height\": 6,\n",
    "            \"x\": 0,\n",
    "            \"y\": 12\n",
    "        },\n",
    "        \n",
    "        # Row 4: Model Monitor Violations\n",
    "        {\n",
    "            \"type\": \"log\",\n",
    "            \"properties\": {\n",
    "                \"query\": f\"SOURCE '/aws/sagemaker/Endpoints/{endpoint_name}'\\n| fields @timestamp, @message\\n| filter @message like /violation/\\n| sort @timestamp desc\\n| limit 20\",\n",
    "                \"region\": region,\n",
    "                \"title\": \"Recent Monitoring Violations\",\n",
    "                \"stacked\": False\n",
    "            },\n",
    "            \"width\": 24,\n",
    "            \"height\": 6,\n",
    "            \"x\": 0,\n",
    "            \"y\": 18\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Create dashboard\n",
    "try:\n",
    "    cw_client.put_dashboard(\n",
    "        DashboardName=dashboard_name,\n",
    "        DashboardBody=json.dumps(dashboard_body)\n",
    "    )\n",
    "    print(f\"✓ CloudWatch dashboard created: {dashboard_name}\")\n",
    "    print(f\"\\nView dashboard at:\")\n",
    "    print(f\"https://console.aws.amazon.com/cloudwatch/home?region={region}#dashboards:name={dashboard_name}\")\n",
    "except Exception as e:\n",
    "    print(f\"✗ Error creating dashboard: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Query Recent Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query recent endpoint metrics\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "end_time = datetime.now(timezone.utc)\n",
    "start_time = end_time - timedelta(hours=1)\n",
    "\n",
    "def get_metric_statistics(metric_name, namespace='AWS/SageMaker', statistic='Average'):\n",
    "    \"\"\"Helper function to get metric statistics\"\"\"\n",
    "    try:\n",
    "        response = cw_client.get_metric_statistics(\n",
    "            Namespace=namespace,\n",
    "            MetricName=metric_name,\n",
    "            Dimensions=[\n",
    "                {'Name': 'EndpointName', 'Value': endpoint_name},\n",
    "                {'Name': 'VariantName', 'Value': variant_name}\n",
    "            ],\n",
    "            StartTime=start_time,\n",
    "            EndTime=end_time,\n",
    "            Period=300,\n",
    "            Statistics=[statistic]\n",
    "        )\n",
    "        \n",
    "        if response['Datapoints']:\n",
    "            latest = sorted(response['Datapoints'], key=lambda x: x['Timestamp'])[-1]\n",
    "            return latest[statistic]\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        return None\n",
    "\n",
    "print(\"\\n=== Recent Endpoint Metrics (Last Hour) ===\")\n",
    "print(f\"\\nPerformance:\")\n",
    "latency = get_metric_statistics('ModelLatency')\n",
    "if latency:\n",
    "    print(f\"  Average Latency: {latency/1000:.2f}ms\")\n",
    "\n",
    "invocations = get_metric_statistics('Invocations', statistic='Sum')\n",
    "if invocations:\n",
    "    print(f\"  Total Invocations: {invocations:.0f}\")\n",
    "\n",
    "errors = get_metric_statistics('ModelInvocationErrors', statistic='Sum')\n",
    "if errors:\n",
    "    print(f\"  Errors: {errors:.0f}\")\n",
    "    if invocations and invocations > 0:\n",
    "        error_rate = (errors / invocations) * 100\n",
    "        print(f\"  Error Rate: {error_rate:.2f}%\")\n",
    "\n",
    "print(f\"\\nResource Utilization:\")\n",
    "cpu = get_metric_statistics('CPUUtilization', namespace='/aws/sagemaker/Endpoints')\n",
    "if cpu:\n",
    "    print(f\"  CPU: {cpu:.2f}%\")\n",
    "\n",
    "memory = get_metric_statistics('MemoryUtilization', namespace='/aws/sagemaker/Endpoints')\n",
    "if memory:\n",
    "    print(f\"  Memory: {memory:.2f}%\")\n",
    "\n",
    "disk = get_metric_statistics('DiskUtilization', namespace='/aws/sagemaker/Endpoints')\n",
    "if disk:\n",
    "    print(f\"  Disk: {disk:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Generate Monitoring Reports <a id='reports'></a>\n",
    "\n",
    "Generate comprehensive reports for model and data monitoring."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1 List All Monitoring Schedules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all monitoring schedules\n",
    "schedules = sm_client.list_monitoring_schedules(\n",
    "    EndpointName=endpoint_name,\n",
    "    MaxResults=100\n",
    ")\n",
    "\n",
    "print(\"\\n=== Active Monitoring Schedules ===\")\n",
    "for schedule in schedules['MonitoringScheduleSummaries']:\n",
    "    print(f\"\\nSchedule: {schedule['MonitoringScheduleName']}\")\n",
    "    print(f\"  Status: {schedule['MonitoringScheduleStatus']}\")\n",
    "    print(f\"  Type: {schedule.get('MonitoringType', 'DataQuality')}\")\n",
    "    print(f\"  Created: {schedule['CreationTime']}\")\n",
    "    print(f\"  Last Modified: {schedule['LastModifiedTime']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2 Check Latest Monitoring Executions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_latest_execution(schedule_name):\n",
    "    \"\"\"Get the latest execution for a monitoring schedule\"\"\"\n",
    "    try:\n",
    "        executions = sm_client.list_monitoring_executions(\n",
    "            MonitoringScheduleName=schedule_name,\n",
    "            MaxResults=1,\n",
    "            SortBy='CreationTime',\n",
    "            SortOrder='Descending'\n",
    "        )\n",
    "        \n",
    "        if executions['MonitoringExecutionSummaries']:\n",
    "            return executions['MonitoringExecutionSummaries'][0]\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        return None\n",
    "\n",
    "print(\"\\n=== Latest Monitoring Executions ===\")\n",
    "for schedule in schedules['MonitoringScheduleSummaries']:\n",
    "    schedule_name = schedule['MonitoringScheduleName']\n",
    "    execution = get_latest_execution(schedule_name)\n",
    "    \n",
    "    print(f\"\\n{schedule_name}:\")\n",
    "    if execution:\n",
    "        print(f\"  Status: {execution['MonitoringExecutionStatus']}\")\n",
    "        print(f\"  Started: {execution.get('ScheduledTime', 'N/A')}\")\n",
    "        if 'ProcessingJobArn' in execution:\n",
    "            print(f\"  Processing Job: {execution['ProcessingJobArn'].split('/')[-1]}\")\n",
    "    else:\n",
    "        print(\"  No executions yet (schedule may not have run)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.3 Generate Model Quality Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download latest model quality results if available\n",
    "try:\n",
    "    # List files in model quality results location\n",
    "    results_files = S3Downloader.list(model_quality_results_uri)\n",
    "    \n",
    "    if results_files:\n",
    "        print(f\"\\n=== Model Quality Monitoring Results ===\")\n",
    "        print(f\"Found {len(results_files)} result files\")\n",
    "        \n",
    "        # Download the most recent constraint violations report\n",
    "        for file in sorted(results_files, reverse=True):\n",
    "            if 'constraint_violations' in file:\n",
    "                local_file = S3Downloader.download(file, \".\")\n",
    "                with open(local_file[0], 'r') as f:\n",
    "                    violations = json.load(f)\n",
    "                \n",
    "                if violations.get('violations'):\n",
    "                    print(f\"\\n⚠️ Found {len(violations['violations'])} violations:\")\n",
    "                    for violation in violations['violations']:\n",
    "                        print(f\"  - {violation.get('description', 'Unknown violation')}\")\n",
    "                else:\n",
    "                    print(\"\\n✓ No violations detected\")\n",
    "                break\n",
    "    else:\n",
    "        print(\"\\nNo monitoring results available yet.\")\n",
    "        print(\"Monitoring schedules need to run before results are generated.\")\n",
    "except Exception as e:\n",
    "    print(f\"\\nCannot retrieve model quality results yet: {e}\")\n",
    "    print(\"This is expected if monitoring hasn't run yet.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.4 Generate Data Quality Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download latest data quality results if available\n",
    "try:\n",
    "    results_files = S3Downloader.list(data_quality_results_uri)\n",
    "    \n",
    "    if results_files:\n",
    "        print(f\"\\n=== Data Quality Monitoring Results ===\")\n",
    "        print(f\"Found {len(results_files)} result files\")\n",
    "        \n",
    "        # Download the most recent constraint violations report\n",
    "        for file in sorted(results_files, reverse=True):\n",
    "            if 'constraint_violations' in file:\n",
    "                local_file = S3Downloader.download(file, \".\")\n",
    "                with open(local_file[0], 'r') as f:\n",
    "                    violations = json.load(f)\n",
    "                \n",
    "                if violations.get('violations'):\n",
    "                    print(f\"\\n⚠️ Found {len(violations['violations'])} violations:\")\n",
    "                    for violation in violations['violations']:\n",
    "                        feature = violation.get('feature_name', 'Unknown')\n",
    "                        description = violation.get('description', 'Unknown violation')\n",
    "                        print(f\"  - Feature '{feature}': {description}\")\n",
    "                else:\n",
    "                    print(\"\\n✓ No violations detected\")\n",
    "                break\n",
    "    else:\n",
    "        print(\"\\nNo monitoring results available yet.\")\n",
    "        print(\"Monitoring schedules need to run before results are generated.\")\n",
    "except Exception as e:\n",
    "    print(f\"\\nCannot retrieve data quality results yet: {e}\")\n",
    "    print(\"This is expected if monitoring hasn't run yet.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.5 Create Comprehensive Monitoring Summary Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate comprehensive monitoring report\n",
    "report = {\n",
    "    \"report_timestamp\": datetime.now(timezone.utc).isoformat(),\n",
    "    \"endpoint_name\": endpoint_name,\n",
    "    \"monitoring_schedules\": [],\n",
    "    \"infrastructure_metrics\": {},\n",
    "    \"alarms\": [],\n",
    "    \"recent_violations\": []\n",
    "}\n",
    "\n",
    "# Add monitoring schedules\n",
    "for schedule in schedules['MonitoringScheduleSummaries']:\n",
    "    report[\"monitoring_schedules\"].append({\n",
    "        \"name\": schedule['MonitoringScheduleName'],\n",
    "        \"status\": schedule['MonitoringScheduleStatus'],\n",
    "        \"type\": schedule.get('MonitoringType', 'DataQuality')\n",
    "    })\n",
    "\n",
    "# Add infrastructure metrics\n",
    "report[\"infrastructure_metrics\"] = {\n",
    "    \"latency_ms\": latency/1000 if latency else None,\n",
    "    \"invocations\": invocations if invocations else 0,\n",
    "    \"errors\": errors if errors else 0,\n",
    "    \"cpu_utilization\": cpu if cpu else None,\n",
    "    \"memory_utilization\": memory if memory else None,\n",
    "    \"disk_utilization\": disk if disk else None\n",
    "}\n",
    "\n",
    "# Add alarms\n",
    "for alarm in alarms['MetricAlarms']:\n",
    "    report[\"alarms\"].append({\n",
    "        \"name\": alarm['AlarmName'],\n",
    "        \"state\": alarm['StateValue'],\n",
    "        \"metric\": alarm.get('MetricName', 'Expression'),\n",
    "        \"threshold\": alarm['Threshold']\n",
    "    })\n",
    "\n",
    "# Save report to S3\n",
    "report_filename = f\"monitoring_report_{datetime.now(timezone.utc):%Y%m%d_%H%M%S}.json\"\n",
    "with open(report_filename, 'w') as f:\n",
    "    json.dump(report, indent=2, fp=f)\n",
    "\n",
    "report_s3_uri = S3Uploader.upload(report_filename, reports_uri)\n",
    "\n",
    "print(f\"\\n✓ Monitoring report generated and saved to:\")\n",
    "print(f\"  {report_s3_uri}\")\n",
    "print(f\"\\n=== Report Summary ===\")\n",
    "print(json.dumps(report, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Testing Monitoring with Sample Data <a id='testing'></a>\n",
    "\n",
    "Send test predictions to generate monitoring data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Uncomment and adapt this to your model's input format\n",
    "\n",
    "# from sagemaker.predictor import Predictor\n",
    "# from sagemaker.serializers import CSVSerializer\n",
    "# from sagemaker.deserializers import JSONDeserializer\n",
    "# \n",
    "# # Create predictor\n",
    "# predictor = Predictor(\n",
    "#     endpoint_name=endpoint_name,\n",
    "#     sagemaker_session=sagemaker_session,\n",
    "#     serializer=CSVSerializer(),\n",
    "#     deserializer=JSONDeserializer()\n",
    "# )\n",
    "# \n",
    "# # Load test data\n",
    "# test_data = df_train_sample.drop(columns=['label'])  # UPDATE column name\n",
    "# \n",
    "# # Send test predictions\n",
    "# print(\"Sending test predictions...\")\n",
    "# for i, row in test_data.iterrows():\n",
    "#     prediction = predictor.predict(row.values.reshape(1, -1))\n",
    "#     print(f\"  Prediction {i+1}: {prediction}\")\n",
    "#     sleep(1)  # Small delay between requests\n",
    "# \n",
    "# print(\"\\n✓ Test predictions sent successfully\")\n",
    "# print(\"Data capture should now have recorded these predictions.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Cleanup <a id='cleanup'></a>\n",
    "\n",
    "**Important:** Run these cells to delete resources and avoid charges.\n",
    "\n",
    "**⚠️ Warning:** This will delete all monitoring schedules, alarms, and the dashboard. Only run after you've completed your demonstration and documentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.1 Delete Monitoring Schedules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleting monitoring schedules...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'schedules' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Delete all monitoring schedules\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDeleting monitoring schedules...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m schedule \u001b[38;5;129;01min\u001b[39;00m \u001b[43mschedules\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMonitoringScheduleSummaries\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[1;32m      5\u001b[0m     schedule_name \u001b[38;5;241m=\u001b[39m schedule[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMonitoringScheduleName\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;31mNameError\u001b[0m: name 'schedules' is not defined"
     ]
    }
   ],
   "source": [
    "# Delete all monitoring schedules\n",
    "print(\"Deleting monitoring schedules...\")\n",
    "\n",
    "for schedule in schedules['MonitoringScheduleSummaries']:\n",
    "    schedule_name = schedule['MonitoringScheduleName']\n",
    "    try:\n",
    "        sm_client.delete_monitoring_schedule(MonitoringScheduleName=schedule_name)\n",
    "        print(f\"  ✓ Deleted: {schedule_name}\")\n",
    "    except Exception as e:\n",
    "        print(f\"  ✗ Error deleting {schedule_name}: {e}\")\n",
    "\n",
    "print(\"\\nWaiting for deletions to complete...\")\n",
    "sleep(60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.2 Delete CloudWatch Alarms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleting CloudWatch alarms...\n",
      "  ✗ Error deleting alarms: name 'alarms' is not defined\n"
     ]
    }
   ],
   "source": [
    "# Delete all CloudWatch alarms for this endpoint\n",
    "print(\"Deleting CloudWatch alarms...\")\n",
    "\n",
    "try:\n",
    "    alarm_names = [alarm['AlarmName'] for alarm in alarms['MetricAlarms']]\n",
    "    if alarm_names:\n",
    "        cw_client.delete_alarms(AlarmNames=alarm_names)\n",
    "        print(f\"  ✓ Deleted {len(alarm_names)} alarms\")\n",
    "    else:\n",
    "        print(\"  No alarms to delete\")\n",
    "except Exception as e:\n",
    "    print(f\"  ✗ Error deleting alarms: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.3 Delete CloudWatch Dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✗ Error deleting dashboard: name 'cw_client' is not defined\n"
     ]
    }
   ],
   "source": [
    "# Delete CloudWatch dashboard\n",
    "try:\n",
    "    cw_client.delete_dashboards(DashboardNames=[dashboard_name])\n",
    "    print(f\"✓ Deleted dashboard: {dashboard_name}\")\n",
    "except Exception as e:\n",
    "    print(f\"✗ Error deleting dashboard: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.4 Optional: Delete S3 Monitoring Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to delete S3 monitoring data\n",
    "# This will delete all captured data, baselines, and reports\n",
    "\n",
    "# print(\"Deleting S3 monitoring data...\")\n",
    "# \n",
    "# s3_resource = boto3.resource('s3')\n",
    "# bucket_resource = s3_resource.Bucket(bucket)\n",
    "# \n",
    "# # Delete monitoring prefix\n",
    "# bucket_resource.objects.filter(Prefix=f\"{prefix}/monitoring/\").delete()\n",
    "# \n",
    "# print(f\"✓ Deleted all S3 objects under s3://{bucket}/{prefix}/monitoring/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.5 Keep Endpoint Running (Optional)\n",
    "\n",
    "**Note:** By default, we do NOT delete the endpoint as it may be needed for other project deliverables. \n",
    "If you want to delete the endpoint as well, uncomment and run the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to delete the endpoint\n",
    "# \n",
    "# print(\"Deleting endpoint...\")\n",
    "# predictor = Predictor(\n",
    "#     endpoint_name=endpoint_name,\n",
    "#     sagemaker_session=sagemaker_session\n",
    "# )\n",
    "# predictor.delete_endpoint(delete_endpoint_config=True)\n",
    "# print(\"✓ Endpoint deleted\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "This notebook has implemented comprehensive monitoring for your ML system:\n",
    "\n",
    "✅ **Model Quality Monitoring** - Tracks prediction accuracy over time\n",
    "\n",
    "✅ **Data Quality Monitoring** - Detects data drift and quality issues\n",
    "\n",
    "✅ **Model Bias Monitoring** - Monitors for fairness issues (if applicable)\n",
    "\n",
    "✅ **Infrastructure Monitoring** - CloudWatch alarms for latency, errors, CPU, memory\n",
    "\n",
    "✅ **CloudWatch Dashboard** - Centralized visualization of all metrics\n",
    "\n",
    "✅ **Automated Reporting** - Comprehensive monitoring reports\n",
    "\n",
    "### Next Steps for Module 5:\n",
    "\n",
    "1. **Take Screenshots** - Capture dashboard, alarms, and monitoring schedules for your video demonstration\n",
    "\n",
    "2. **Update Design Document** - Document your monitoring approach in the ML Design Document\n",
    "\n",
    "3. **Wait for Executions** - Monitoring schedules run daily, so come back in 24-48 hours to see results\n",
    "\n",
    "4. **Generate Sample Violations** - (Optional) Intentionally send bad data to trigger violations for demonstration\n",
    "\n",
    "5. **Prepare for Module 6** - CI/CD will integrate with this monitoring infrastructure\n",
    "\n",
    "### Module 5 Deliverable Checklist:\n",
    "\n",
    "- [ ] Model monitors implemented\n",
    "- [ ] Data monitors implemented\n",
    "- [ ] Infrastructure monitors implemented\n",
    "- [ ] CloudWatch dashboard created\n",
    "- [ ] Model and data reports generated\n",
    "- [ ] Screenshots captured for documentation\n",
    "- [ ] Design document updated with monitoring details\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
